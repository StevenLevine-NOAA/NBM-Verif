{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRgU+GvsIUJByAXKuoa5XB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StevenLevine-NOAA/NBM-Verif/blob/main/Examine_the_Bulls_Eye.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook looks at verious METAR and RAWS sites to help the user determine whether an ob driven measle/bulls eye exists at that point.\n",
        "\n",
        "The code identifies the grid point in question and the 8 points surround it, interrogating all of them and plotting to derive a potential bulls eye.\n",
        "\n",
        "Another option/cell shows the magnitude of the bulls eye over time.\n",
        "\n",
        "Note that for now, you will need to know the i/j location of the ob site in the NDFD/NBM grid for this to work."
      ],
      "metadata": {
        "id": "qZg0Q8cKx6z1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLHiW_KCb8g6"
      },
      "outputs": [],
      "source": [
        "#@title Initialize Notebook Part 1\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Initialize Notebook Part 2\n",
        "!mamba install -q -c conda-forge cartopy contextily pyproj pyepsg pygrib geopy #netCDF4\n",
        "import numpy as np\n",
        "#from scipy.interpolate import CubicSpline as cs, UnivariateSpline as us\n",
        "import pandas as pd\n",
        "from urllib.request import urlretrieve, urlopen\n",
        "import requests\n",
        "from datetime import datetime, timedelta\n",
        "import pygrib\n",
        "import pyproj\n",
        "from pyproj import Proj, transform\n",
        "import os, re, traceback\n",
        "from geopy import distance\n",
        "\n",
        "import matplotlib\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "#from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "import matplotlib.patches as mpatches\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.axes as maxes\n",
        "import matplotlib.patheffects as PathEffects\n",
        "import matplotlib.dates as mdates\n",
        "from matplotlib.path import Path\n",
        "from matplotlib.textpath import TextToPath\n",
        "import matplotlib.gridspec as gridspec\n",
        "from matplotlib.font_manager import FontProperties\n",
        "matplotlib.rcParams['font.sans-serif'] = 'Liberation Sans'\n",
        "matplotlib.rcParams['font.family'] = \"sans-serif\"\n",
        "from matplotlib.cm import get_cmap\n",
        "#import seaborn as sns\n",
        "\n",
        "from cartopy import crs as ccrs, feature as cfeature\n",
        "from cartopy.io.shapereader import Reader\n",
        "from cartopy.feature import ShapelyFeature\n",
        "import contextily as cx\n",
        "import itertools\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "b5qNr54kcCnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Date set up, core_valid_time should be a multiple of 24, beginning with 48 for minT and 36 for maxT.  All forecasts originate at 12Z."
      ],
      "metadata": {
        "id": "EfQ3TmO97HQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Date Set Up\n",
        "element = \"mint\" #@param [\"maxt\",\"mint\"]\n",
        "start_date = \"2023-02-01\" #@param {type:\"date\"}\n",
        "nbm_start_date=datetime.strptime(start_date,'%Y-%m-%d')\n",
        "end_date = \"2023-03-01\" #@param {type:\"date\"}\n",
        "nbm_end_date=datetime.strptime(end_date,'%Y-%m-%d')\n",
        "core_valid_time = 48 #@param {type:\"integer\"}\n",
        "#core time should be muliple of 24, beginning with 48 for mint and 36 for maxt\n",
        "point_i = 775 #@param {type:\"integer\"}\n",
        "point_j = 379 #@param {type:\"integer\"}\n",
        "nbm_init_hour = 12 \n",
        "if element == \"maxt\":\n",
        "  nbm_core_valid_hour=\"00\"\n",
        "  #core_init = nbm_init + timedelta(hours=7)\n",
        "elif element == \"mint\":\n",
        "  nbm_core_valid_hour=\"12\"\n",
        "  #core_init = nbm_init + timedelta(hours=7)\n",
        "elif element == \"qpf\":\n",
        "  nbm_core_valid_hour=\"12\"\n",
        "\n",
        "gridBox = {}\n",
        "gridBox[\"NorthWest\"] = (point_i-1,point_j+1)\n",
        "gridBox[\"North\"] = (point_i,point_j+1)\n",
        "gridBox[\"NorthEast\"] = (point_i+1,point_j+1)\n",
        "gridBox[\"West\"] = (point_i-1,point_j)\n",
        "gridBox[\"Point\"] = (point_i,point_j)\n",
        "gridBox[\"East\"] = (point_i+1,point_j)\n",
        "gridBox[\"SouthWest\"] = (point_i-1,point_j-1)\n",
        "gridBox[\"South\"] = (point_i,point_j-1)\n",
        "gridBox[\"SouthEast\"] = (point_i+1,point_j-1)"
      ],
      "metadata": {
        "id": "5u7ZDw9ccMb1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Pull the Gribs\n",
        "\n",
        "###############################\n",
        "########Subroutines############\n",
        "###############################\n",
        "\n",
        "#subroutines - download_subset\n",
        "def download_subset(remote_url, remote_file, local_filename):\n",
        "  print(\"   > Downloading a subset of NBM gribs\")\n",
        "  local_file = \"nbm/\"+local_filename\n",
        "  if \"qmd\" in remote_file:\n",
        "    if element == \"maxt\":\n",
        "      if (int(nbm_qmd_forecasthour_start) % 24 == 0) and (int(nbm_qmd_forecasthour) % 24 ==0):\n",
        "        search_string = f':TMP:2 m above ground:{str(int(int(nbm_qmd_forecasthour_start)/24))}-{str(int(int(nbm_qmd_forecasthour)/24))} day max fcst:'\n",
        "      else:\n",
        "        search_string = f':TMP:2 m above ground:{str(int(nbm_qmd_forecasthour_start))}-{str(int(nbm_qmd_forecasthour))} hour max fcst:'\n",
        "    elif element == \"mint\":\n",
        "      if (int(nbm_qmd_forecasthour_start) % 24 == 0) and (int(nbm_qmd_forecasthour) % 24 ==0):\n",
        "        search_string = f':TMP:2 m above ground:{str(int(int(nbm_qmd_forecasthour_start)/24))}-{str(int(int(nbm_qmd_forecasthour)/24))} day min fcst:'\n",
        "      else:\n",
        "        search_string = f':TMP:2 m above ground:{str(int(nbm_qmd_forecasthour_start))}-{str(int(nbm_qmd_forecasthour))} hour min fcst:'\n",
        "    elif element == \"qpf\":\n",
        "      if (int(nbm_qmd_forecasthour_start) % 24 == 0) and (int(nbm_qmd_forecasthour) % 24 ==0):\n",
        "        search_string = f':APCP:surface:{str(int(int(nbm_qmd_forecasthour_start)/24))}-{str(int(int(nbm_qmd_forecasthour)/24))} day acc fcst:'\n",
        "      else:\n",
        "        search_string = f':APCP:surface:{str(int(nbm_qmd_forecasthour_start))}-{str(int(nbm_qmd_forecasthour))} hour acc fcst:'\n",
        "  elif \"core\" in remote_file:\n",
        "    if element == \"maxt\":\n",
        "      search_string = f':TMAX:2 m above ground:{str(int(nbm_core_forecasthour_start))}-{str(int(nbm_core_forecasthour))} hour max fcst:'\n",
        "    elif element == \"mint\":\n",
        "      search_string = f':TMIN:2 m above ground:{str(int(nbm_core_forecasthour_start))}-{str(int(nbm_core_forecasthour))} hour min fcst:'\n",
        "    elif element == \"temp\":\n",
        "      search_string = f':TMP:2 m above ground:{str(int(nbm_core_forecasthour))} hour fcst:'\n",
        "    elif element == \"dwpt\":\n",
        "      search_string = f':DWPT:2 m above ground:{str(int(nbm_core_forecasthour))} hour fcst:'\n",
        "    elif element == \"wspd\":\n",
        "      search_string = f':WIND:10 m above ground:{str(int(nbm_core_forecasthour))} hour fcst:'\n",
        "  #print(search_string)\n",
        "  idx = remote_url+\".idx\"\n",
        "  r = requests.get(idx)\n",
        "  if not r.ok: \n",
        "    print('     ❌ SORRY! Status Code:', r.status_code, r.reason)\n",
        "    print(f'      ❌ It does not look like the index file exists: {idx}')\n",
        "\n",
        "  lines = r.text.split('\\n')\n",
        "  expr = re.compile(search_string)\n",
        "  byte_ranges = {}\n",
        "  for n, line in enumerate(lines, start=1):\n",
        "      # n is the line number (starting from 1) so that when we call for \n",
        "      # `lines[n]` it will give us the next line. (Clear as mud??)\n",
        "\n",
        "      # Use the compiled regular expression to search the line\n",
        "      if expr.search(line):   \n",
        "          # aka, if the line contains the string we are looking for...\n",
        "\n",
        "          # Get the beginning byte in the line we found\n",
        "          parts = line.split(':')\n",
        "          rangestart = int(parts[1])\n",
        "\n",
        "          # Get the beginning byte in the next line...\n",
        "          if n+1 < len(lines):\n",
        "              # ...if there is a next line\n",
        "              parts = lines[n].split(':')\n",
        "              rangeend = int(parts[1])\n",
        "          else:\n",
        "              # ...if there isn't a next line, then go to the end of the file.\n",
        "              rangeend = ''\n",
        "\n",
        "          # Store the byte-range string in our dictionary, \n",
        "          # and keep the line information too so we can refer back to it.\n",
        "          byte_ranges[f'{rangestart}-{rangeend}'] = line\n",
        "          #print(line)\n",
        "  for i, (byteRange, line) in enumerate(byte_ranges.items()):\n",
        "        \n",
        "        if i == 0:\n",
        "            # If we are working on the first item, overwrite the existing file.\n",
        "            curl = f'curl -s --range {byteRange} {remote_url} > {local_file}'\n",
        "        else:\n",
        "            # If we are working on not the first item, append the existing file.\n",
        "            curl = f'curl -s --range {byteRange} {remote_url} >> {local_file}'\n",
        "        try:    \n",
        "          num, byte, date, var, level, forecast, _ = line.split(':')\n",
        "        except:\n",
        "          pass\n",
        "        \n",
        "        #print(f'  Downloading GRIB line [{num:>3}]: variable={var}, level={level}, forecast={forecast}')    \n",
        "        os.system(curl)\n",
        "    \n",
        "  if os.path.exists(local_file):\n",
        "      print(f'      ✅ Success! Searched for [{search_string}] and got [{len(byte_ranges)}] GRIB fields and saved as {local_file}')\n",
        "      return local_file\n",
        "  else:\n",
        "      print(print(f'      ❌ Unsuccessful! Searched for [{search_string}] and did not find anything!'))\n",
        "\n",
        "\n",
        "#subroutine - daterange\n",
        "def daterange(start_date,end_date):\n",
        "  for n in range(int((end_date - start_date).days) + 1):\n",
        "    yield start_date + timedelta(n)\n",
        "\n",
        "#subroutine - K to F\n",
        "def K_to_F(kelvin):\n",
        "  fahrenheit = 1.8*(kelvin-273)+32.\n",
        "  return fahrenheit\n",
        "\n",
        "#subroutine - mm to in\n",
        "def mm_to_in(millimeters):\n",
        "  inches = millimeters * 0.0393701\n",
        "  return inches\n",
        "\n",
        "#########################################\n",
        "#######Start of actual processing########\n",
        "#########################################\n",
        "fcst=pd.DataFrame(columns=[\"dates\",\"SouthWest\",\"South\",\"SouthEast\",\"West\",\"Point\",\"East\",\"NorthWest\",\"NorthEast\"])\n",
        "dtdate=[]\n",
        "lls=[]\n",
        "lcs=[]\n",
        "lrs=[]\n",
        "cls=[]\n",
        "ccs=[]\n",
        "crs=[]\n",
        "uls=[]\n",
        "ucs=[]\n",
        "urs=[]\n",
        "for nbmdate in daterange(nbm_start_date,nbm_end_date):\n",
        "  dtdate.append(nbmdate)\n",
        "  nbm_init=nbmdate+timedelta(hours=int(nbm_init_hour))\n",
        "  nbm_core_forecasthour=core_valid_time\n",
        "  if element == \"mint\" or element == \"maxt\":\n",
        "    core_init = nbm_init + timedelta(hours=7)\n",
        "    nbm_core_valid_end_datetime = nbm_init + timedelta(hours=int(nbm_core_forecasthour))\n",
        "    nbm_core_fhdelta = nbm_core_valid_end_datetime - core_init\n",
        "  else:\n",
        "    core_init = nbm_init\n",
        "    nbm_core_valid_end_datetime = nbm_init\n",
        "    nbm_core_fhdelta = nbm_core_valid_end_datetime - core_init\n",
        "  nbm_core_forecasthour = nbm_core_fhdelta.total_seconds() / 3600.\n",
        "  nbm_core_forecasthour_start = nbm_core_forecasthour - 12\n",
        "  #get file names\n",
        "  nbm_init_filen_core = core_init.strftime('%Y%m%d') + \"_\" + core_init.strftime('%H')\n",
        "  nbm_url_base = \"https://noaa-nbm-grib2-pds.s3.amazonaws.com/blend.\"+nbm_init.strftime('%Y%m%d') \\\n",
        "              +\"/\"+nbm_init.strftime('%H')+\"/\"\n",
        "  nbm_url_base_core = \"https://noaa-nbm-grib2-pds.s3.amazonaws.com/blend.\"+core_init.strftime('%Y%m%d') \\\n",
        "              +\"/\"+core_init.strftime('%H')+\"/\"\n",
        "  temp_vars = [\"maxt\",\"mint\",\"temp\",\"dwpt\"]\n",
        "  #if (element == \"qpf\"):\n",
        "  #  detr_file = f'blend.t{int(nbm_init_hour):02}z.qmd.f{int(nbm_qmd_forecasthour):03}.co.grib2'\n",
        "  #  detr_file_subset = f'blend.t{int(nbm_init_hour):02}z.qmd.{nbm_init_filen}{nbm_init_filen}f{int(nbm_qmd_forecasthour):03}.co.{element}_subset.grib2'\n",
        "  #  if (int(nbm_qmd_forecasthour) < 12):\n",
        "  #    break\n",
        "  #  detr_url = nbm_url_base+\"qmd/\"+detr_file\n",
        "\n",
        "  # elif any(te in element for te in temp_vars):\n",
        "  if any(te in element for te in temp_vars):\n",
        "    detr_file = f\"blend.t{int(core_init.strftime('%H')):02}z.core.f{int(nbm_core_forecasthour):03}.co.grib2\"\n",
        "    detr_file_subset = f\"blend.t{int(core_init.strftime('%H')):02}z.core.{nbm_init_filen_core}f{int(nbm_core_forecasthour):03}.co.{element}_subset.grib2\"\n",
        "    if (int(nbm_core_forecasthour) < 12):\n",
        "      break\n",
        "    detr_url = nbm_url_base_core+\"core/\"+detr_file\n",
        "\n",
        "  #download file if we don't have it yet\n",
        "  if os.path.exists(\"nbm/\"+detr_file_subset):\n",
        "    print(\"   > NBM deterministic already exists\")\n",
        "  else:\n",
        "    print(\"   > Getting NBM deterministic\")\n",
        "    if os.path.exists(\"nbm\"):\n",
        "      pass\n",
        "    else:\n",
        "      os.mkdir(\"nbm\")\n",
        "    download_subset(detr_url, detr_file, detr_file_subset)\n",
        "  #extract deterministic values\n",
        "  nbmd = pygrib.open(\"nbm/\"+detr_file_subset)\n",
        "  if element == \"maxt\":\n",
        "    deterministic = nbmd.select(name=\"Maximum temperature\",lengthOfTimeRange=12, stepTypeInternal=\"max\")[0]\n",
        "    deterministic_array = K_to_F(deterministic.values)\n",
        "  elif element == \"mint\":\n",
        "    deterministic = nbmd.select(name=\"Minimum temperature\",lengthOfTimeRange=12, stepTypeInternal=\"min\")[0]\n",
        "    deterministic_array = K_to_F(deterministic.values)\n",
        "  elif element == \"qpf\":\n",
        "    deterministic = nbmd.select(name=\"Total Precipitation\",lengthOfTimeRange=24)[-1]\n",
        "    deterministic_array = mm_to_in(deterministic.values)\n",
        "  nbmlats, nbmlons = deterministic.latlons()\n",
        "  #testlat=nbmlats[point_i,point_j]\n",
        "  #testlon=nbmlons[point_i,point_j]\n",
        "  #print(\"Test lat/lon = \" + str(testlat) + \", \" + str(testlon))\n",
        "  nbmd.close()\n",
        "  lls.append(deterministic_array[gridBox[\"SouthWest\"]])\n",
        "  lcs.append(deterministic_array[gridBox[\"South\"]])\n",
        "  lrs.append(deterministic_array[gridBox[\"SouthEast\"]])\n",
        "  cls.append(deterministic_array[gridBox[\"West\"]])\n",
        "  ccs.append(deterministic_array[gridBox[\"Point\"]])\n",
        "  crs.append(deterministic_array[gridBox[\"East\"]])\n",
        "  uls.append(deterministic_array[gridBox[\"NorthWest\"]])\n",
        "  ucs.append(deterministic_array[gridBox[\"North\"]])\n",
        "  urs.append(deterministic_array[gridBox[\"NorthEast\"]])\n",
        "fcst[\"dates\"] = dtdate\n",
        "fcst[\"SouthWest\"] = lls\n",
        "fcst[\"South\"] = lcs\n",
        "fcst[\"SouthEast\"] = lrs\n",
        "fcst[\"West\"] = cls\n",
        "fcst[\"Point\"] = ccs\n",
        "fcst[\"East\"] = crs\n",
        "fcst[\"NorthWest\"] = uls\n",
        "fcst[\"North\"] = ucs\n",
        "fcst[\"NorthEast\"] = urs\n",
        "fcst.set_index(\"dates\",inplace=True)"
      ],
      "metadata": {
        "id": "H885xmfzioT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Calculate Differences\n",
        "fcst[\"DMax\"]=abs(fcst.loc[:,~fcst.columns.isin(['Point'])].max(axis=1)-fcst['Point'])\n",
        "fcst[\"DMin\"]=abs(fcst.loc[:,~fcst.columns.isin(['Point','DMax'])].min(axis=1)-fcst['Point'])\n",
        "fcst[\"Diff\"]=fcst[[\"DMax\",\"DMin\"]].min(axis=1)\n",
        "fcst"
      ],
      "metadata": {
        "id": "sc7wy08yaYPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Make Time Series Plot Of Values\n",
        "fig=plt.figure(constrained_layout=False,figsize=(22,16),dpi=80)\n",
        "grid=fig.add_gridspec(1,1)\n",
        "ax=fig.add_subplot(1,1,1)\n",
        "pts = gridBox.keys()\n",
        "coldict={\"NorthWest\":\"purple\",\"North\":\"red\",\"NorthEast\":\"darkorange\",\"East\":\"yellow\",\"SouthEast\":\"yellowgreen\",\"South\":\"green\",\"SouthWest\":\"cyan\",\"West\":\"blue\",\"Point\":\"black\"}\n",
        "for npoint in coldict.keys():\n",
        "  fcst.plot(ax=ax,use_index=True,y=npoint,label=npoint,grid=True,marker='o',markersize=3,linewidth=2,color=coldict[npoint])\n",
        "ax.set_xlabel(\"Forecast Made\",fontdict={'fontsize':20})\n",
        "ax.set_ylabel(\"Forecast Value\",fontdict={'fontsize':20})\n",
        "#ax.xaxis.set_major_locator(mdates.DayLocator())\n",
        "#ax.xaxis.set_major_formatter(mdates.DateFormatter('%d\\n%b'))\n",
        "#ax.tick_params(axis='both',which='both',labelsize=15)\n",
        "#ax.grid(visible='True',axis='both')\n",
        "#ax2=ax.twinx()\n",
        "#fcst.plot(ax=ax,use_index=True,y=\"Diff\",marker='o',markersize=3,linewidth=2,color='black',linestyle='dashed')\n",
        "#ax2.set_ylabel(\"Point/Surrounding Min\",fontdict={'fontsize':20})\n",
        "ax.tick_params(axis='y',which='both',labelsize=15)\n",
        "ax.xaxis.set_major_locator(mdates.DayLocator())\n",
        "ax.xaxis.set_major_formatter(mdates.DateFormatter('%d\\n%b'))\n",
        "ax.tick_params(axis='both',which='both',labelsize=15)\n",
        "ax.grid(visible='True',axis='both')\n",
        "ax.legend(loc='lower center',bbox_to_anchor=[0.5,1.00],fancybox=True,shadow=True,fontsize='x-large',ncol=9)\n",
        "#ax.axvline(datetime(2023,2,3),linestyle='dashed',color='magenta')\n",
        "title_string=\"Time series of \" + str(core_valid_time) + \" hour \" + element + \" forecasts valid near site\"\n",
        "fig.text(0.5,0.92,title_string,horizontalalignment='center',verticalalignment='bottom',weight='bold',fontsize=20)\n",
        "fig.savefig('neighbor_points.png')"
      ],
      "metadata": {
        "id": "Cw2O5QqxuwLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Make Time Series of Difference\n",
        "figb=plt.figure(constrained_layout=False,figsize=(22,16))\n",
        "grid=figb.add_gridspec(1,1)\n",
        "axb=figb.add_subplot(1,1,1)\n",
        "fcst.plot(ax=axb,use_index=True,y=\"Diff\",marker='o',markersize=3,linewidth=2,color='black',linestyle='dashed')\n",
        "axb.set_xlabel(\"Forecast Made\",fontdict={'fontsize':20})\n",
        "axb.set_ylabel(\"Point/Surrounding Difference\",fontdict={'fontsize':20})\n",
        "axb.tick_params(axis='both',which='both',labelsize=15)\n",
        "axb.xaxis.set_major_locator(mdates.DayLocator())\n",
        "axb.xaxis.set_major_formatter(mdates.DateFormatter('%d\\n%b'))\n",
        "axb.grid(visible='True',axis='both')\n",
        "#axb.axvline(datetime(2023,2,3),linestyle='dashed',color='magenta')\n",
        "title_string=\"Time Series of minimum difference between point and surroundings\"\n",
        "figb.text(0.5,0.92,title_string,horizontalalignment='center',verticalalignment='bottom',weight='bold',fontsize=20)\n",
        "figb.savefig('bullseye_diff.png')"
      ],
      "metadata": {
        "id": "CnaHUXOikRF0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}