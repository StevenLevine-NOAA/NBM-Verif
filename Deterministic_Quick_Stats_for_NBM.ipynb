{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMfEsG0loJB6zLBmmROktqB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StevenLevine-NOAA/NBM-Verif/blob/notebooks/Deterministic_Quick_Stats_for_NBM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ndEeFdsdCqO5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccbb6927-8573-4554-b9ad-5be4889915ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m✨🍰✨ Everything looks OK!\n"
          ]
        }
      ],
      "source": [
        "#@title Initialize Notebook Part 1\n",
        "!pip install -q condacolab #cartopy contextily pyproj pyepsg pygrib netCDF4\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Initialize Notebook Part 2\n",
        "condacolab.check()\n",
        "#!rm -rf /usr/local/conda-meta/pinned\n",
        "!mamba install -q cartopy contextily pyproj pyepsg pygrib scikit-learn netCDF4\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from urllib.request import urlretrieve, urlopen\n",
        "import requests\n",
        "from datetime import datetime, timedelta\n",
        "import json\n",
        "from netCDF4 import Dataset\n",
        "import pygrib\n",
        "import pyproj\n",
        "from pyproj import Proj, transform\n",
        "import os, re, traceback\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import matplotlib\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "#from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "import matplotlib.patches as mpatches\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.axes as maxes\n",
        "import matplotlib.patheffects as PathEffects\n",
        "from matplotlib.path import Path\n",
        "from matplotlib.textpath import TextToPath\n",
        "import matplotlib.gridspec as gridspec\n",
        "from matplotlib.font_manager import FontProperties\n",
        "matplotlib.rcParams['font.sans-serif'] = 'Liberation Sans'\n",
        "matplotlib.rcParams['font.family'] = \"sans-serif\"\n",
        "from matplotlib.cm import get_cmap\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.metrics import mean_squared_error,explained_variance_score,mean_absolute_error\n",
        "import math\n",
        "\n",
        "from cartopy import crs as ccrs, feature as cfeature\n",
        "from cartopy.io.shapereader import Reader\n",
        "from cartopy.feature import ShapelyFeature\n",
        "#import contextily as cx\n",
        "import itertools"
      ],
      "metadata": {
        "id": "fTs8Dc2BCyZp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8f73a99-be8e-4e90-93a4-8211bf9ebac4"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✨🍰✨ Everything looks OK!\n",
            "/usr/local/lib/python3.10/site-packages/conda_package_streaming/package_streaming.py:19: UserWarning: zstandard could not be imported. Running without .conda support.\n",
            "  warnings.warn(\"zstandard could not be imported. Running without .conda support.\")\n",
            "/usr/local/lib/python3.10/site-packages/conda_package_handling/api.py:29: UserWarning: Install zstandard Python bindings for .conda support\n",
            "  _warnings.warn(\"Install zstandard Python bindings for .conda support\")\n",
            "/usr/local/lib/python3.10/site-packages/conda_package_streaming/package_streaming.py:19: UserWarning: zstandard could not be imported. Running without .conda support.\n",
            "  warnings.warn(\"zstandard could not be imported. Running without .conda support.\")\n",
            "/usr/local/lib/python3.10/site-packages/conda_package_handling/api.py:29: UserWarning: Install zstandard Python bindings for .conda support\n",
            "  _warnings.warn(\"Install zstandard Python bindings for .conda support\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Case Information and subroutines { display-mode: \"form\" }\n",
        "element = \"temp\" #@param [\"temp\",\"maxt\",\"mint\",\"dwpt\",\"wspd\",\"maxwind\",\"maxgust\",\"qpf01\",\"qpf06\",\"qpf12\",\"ceil\",\"vis\",\"gust\"]\n",
        "valid_date = \"2023-12-19\" #@param {type:\"date\"}\n",
        "valid_hour = 18 #@param {type:\"slider\", min:0, max:23, step:1}\n",
        "use_stageiv = False #@param {type:\"boolean\"}\n",
        "use_nohrsc = False #@param {type:\"boolean\"}\n",
        "lookback_hours = 60 #@param {type:\"slider\", min:0, max:188, setp:3}\n",
        "region_selection = \"CWA\" #@param [\"WR\", \"SR\", \"CR\", \"ER\", \"CONUS\", \"CWA\"]\n",
        "cwa_id = \"LWX\" #@param {type:\"string\"}\n",
        "network_selection = \"NWS+RAWS\" #@param [\"NWS\", \"RAWS\", \"NWS+RAWS\", \"NWS+RAWS+HADS\", \"ALL\", \"CUSTOM\", \"LIST\"]\n",
        "export_csv = True #@param {type:\"boolean\"}\n",
        "#@markdown Light or dark theme plots?\n",
        "plot_style = \"dark\" #@param [\"light\", \"dark\"]\n",
        "\n",
        "if region_selection == \"CONUS\":\n",
        "  region_list = [\"WR\", \"CR\", \"SR\", \"ER\"]\n",
        "elif region_selection == \"CWA\":\n",
        "  region_list = [cwa_id]\n",
        "else:\n",
        "  region_list = [region_selection]\n",
        "\n",
        "def cwa_list(input_region):\n",
        "  region_dict ={\"WR\":\"BYZ,BOI,LKN,EKA,FGZ,GGW,TFX,VEF,LOX,MFR,MTR,MSO,PDT,PSR,PIH,PQR,REV,STO,SLC,SGX,HNX,SEW,OTX,TWC\",\n",
        "              \"CR\":\"ABR,BIS,CYS,LOT,DVN,BOU,DMX,DTX,DDC,DLH,FGF,GLD,GJT,GRR,GRB,GID,IND,JKL,EAX,ARX,ILX,LMK,MQT,MKX,MPX,LBF,APX,IWX,OAX,PAH,PUB,UNR,RIW,FSD,SGF,LSX,TOP,ICT\",\n",
        "              \"ER\":\"ALY,LWX,BGM,BOX,BUF,BTV,CAR,CTP,RLX,CHS,ILN,CLE,CAE,GSP,MHX,OKX,PHI,PBZ,GYX,RAH,RNK,AKQ,ILM\",\n",
        "              \"SR\":\"ABQ,AMA,FFC,EWX,BMX,BRO,CRP,EPZ,FWD,HGX,HUN,JAN,JAX,KEY,MRX,LCH,LZK,LUB,MLB,MEG,MFL,MOB,MAF,OHX,LIX,OUN,SJT,SHV,TAE,TBW,TSA\"}\n",
        "  if (input_region in [\"WR\", \"CR\", \"SR\", \"ER\"]):\n",
        "    cwas_list = region_dict[input_region]\n",
        "  else:\n",
        "    cwas_list = input_region\n",
        "  return cwas_list\n",
        "\n",
        "nbm_valid = datetime.strptime(valid_date,'%Y-%m-%d') + timedelta(hours=valid_hour)\n",
        "lookback_range=np.arange(0,lookback_hours,3)\n",
        "nbm_init = nbm_valid - timedelta(hours=lookback_hours)\n",
        "\n",
        "current_datetime = datetime.now()\n",
        "\n",
        "def K_to_F(kelvin):\n",
        "  fahrenheit = 1.8*(kelvin-273)+32.\n",
        "  return fahrenheit\n",
        "\n",
        "def C_to_F(celsius):\n",
        "  farenheit=(1.8*celsius)+32.\n",
        "  return farenheit\n",
        "\n",
        "def mm_to_in(millimeters):\n",
        "  inches = millimeters * 0.0393701\n",
        "  return inches\n",
        "\n",
        "def mps_to_kts(mps):\n",
        "  kts = mps * 1.94384\n",
        "  return kts\n",
        "\n",
        "def meters_to_in(meters):\n",
        "  inches = meters*39.3701\n",
        "  return inches\n",
        "\n",
        "def miles_to_meters(miles):\n",
        "  meters = miles*1609.34\n",
        "  return meters\n",
        "\n",
        "def ft_to_m(feet):\n",
        "  meters = feet*0.3048\n",
        "  return meters\n",
        "\n",
        "def ll_to_index(datalons, datalats, loclon, loclat):\n",
        "  abslat = np.abs(datalats-loclat)\n",
        "  abslon = np.abs(datalons-loclon)\n",
        "  c = np.maximum(abslon, abslat)\n",
        "  latlon_idx_flat = np.argmin(c)\n",
        "  latlon_idx = np.unravel_index(latlon_idx_flat, datalons.shape)\n",
        "  return(latlon_idx)\n",
        "\n",
        "def download_subset(remote_url, remote_file, local_filename):\n",
        "  print(\"   > Downloading a subset of NBM gribs\")\n",
        "  local_file = \"nbm/\"+local_filename\n",
        "  if \"qmd\" in remote_file:\n",
        "    if element == \"maxt\":\n",
        "      if (int(nbm_qmd_forecasthour_start) % 24 == 0) and (int(nbm_qmd_forecasthour) % 24 ==0):\n",
        "        search_string = f':TMP:2 m above ground:{str(int(int(nbm_qmd_forecasthour_start)/24))}-{str(int(int(nbm_qmd_forecasthour)/24))} day max fcst:'\n",
        "      else:\n",
        "        search_string = f':TMP:2 m above ground:{str(int(nbm_qmd_forecasthour_start))}-{str(int(nbm_qmd_forecasthour))} hour max fcst:'\n",
        "    elif element == \"mint\":\n",
        "      if (int(nbm_qmd_forecasthour_start) % 24 == 0) and (int(nbm_qmd_forecasthour) % 24 ==0):\n",
        "        search_string = f':TMP:2 m above ground:{str(int(int(nbm_qmd_forecasthour_start)/24))}-{str(int(int(nbm_qmd_forecasthour)/24))} day min fcst:'\n",
        "      else:\n",
        "        search_string = f':TMP:2 m above ground:{str(int(nbm_qmd_forecasthour_start))}-{str(int(nbm_qmd_forecasthour))} hour min fcst:'\n",
        "    elif element == \"qpf\":\n",
        "      if (int(nbm_qmd_forecasthour_start) % 24 == 0) and (int(nbm_qmd_forecasthour) % 24 ==0):\n",
        "        search_string = f':APCP:surface:{str(int(int(nbm_qmd_forecasthour_start)/24))}-{str(int(int(nbm_qmd_forecasthour)/24))} day acc fcst:'\n",
        "      else:\n",
        "        search_string = f':APCP:surface:{str(int(nbm_qmd_forecasthour_start))}-{str(int(nbm_qmd_forecasthour))} hour acc fcst:'\n",
        "    elif element == \"maxwind\":\n",
        "      if (int(nbm_qmd_forecasthour_start) % 24 == 0) and (int(nbm_qmd_forecasthour) % 24 == 0):\n",
        "        search_string = f':WIND:10 m above ground:{str(int(nbm_qmd_forecasthour_start/24))}-{str(int(nbm_qmd_forecasthour/24))} hour max fcst:'\n",
        "      else:\n",
        "        search_string = f':WIND:10 m above ground:{str(int(nbm_qmd_forecasthour_start))}-{str(int(nbm_qmd_forecasthour))} hour max fcst:'\n",
        "  elif \"core\" in remote_file:\n",
        "    if element == \"maxt\":\n",
        "      search_string = f':TMAX:2 m above ground:{str(int(nbm_core_forecasthour_start))}-{str(int(nbm_core_forecasthour))} hour max fcst:'\n",
        "    elif element == \"mint\":\n",
        "      search_string = f':TMIN:2 m above ground:{str(int(nbm_core_forecasthour_start))}-{str(int(nbm_core_forecasthour))} hour min fcst:'\n",
        "    elif element == \"snow\":\n",
        "      search_string = f':ASNOW:surface:{str(int(nbm_core_forecasthour_start))}-{str(int(nbm_core_forecasthour))} hour acc'\n",
        "  #print(\"Search string = \",search_string)\n",
        "  idx = remote_url+\".idx\"\n",
        "  #print(\"IDX file = \" + idx)\n",
        "  r = requests.get(idx)\n",
        "  if not r.ok:\n",
        "    print('     ❌ SORRY! Status Code:', r.status_code, r.reason)\n",
        "    print(f'      ❌ It does not look like the index file exists: {idx}')\n",
        "\n",
        "  lines = r.text.split('\\n')\n",
        "  expr = re.compile(search_string)\n",
        "  expr\n",
        "  byte_ranges = {}\n",
        "  for n, line in enumerate(lines, start=1):\n",
        "    # n is the line number (starting from 1) so that when we call for\n",
        "    # `lines[n]` it will give us the next line. (Clear as mud??)\n",
        "    # Use the compiled regular expression to search the line\n",
        "    #print(\">> Searching throgh this line: \" + line)\n",
        "    if expr.search(line):\n",
        "      # aka, if the line contains the string we are looking for...\n",
        "      # Get the beginning byte in the line we found\n",
        "      parts = line.split(':')\n",
        "      rangestart = int(parts[1])\n",
        "      # Get the beginning byte in the next line...\n",
        "      if n+1 < len(lines):\n",
        "        # ...if there is a next line\n",
        "        parts = lines[n].split(':')\n",
        "        rangeend = int(parts[1])\n",
        "      else:\n",
        "        # ...if there isn't a next line, then go to the end of the file.\n",
        "        rangeend = ''\n",
        "\n",
        "        # Store the byte-range string in our dictionary,\n",
        "        # and keep the line information too so we can refer back to it.\n",
        "      byte_ranges[f'{rangestart}-{rangeend}'] = line\n",
        "      #print(line)\n",
        "    #else:\n",
        "      #print(\">>>  Could not find search string!\")\n",
        "  #print(\">>  Number of items in byteRange:\" + str(len(byte_ranges)))\n",
        "  for i, (byteRange, line) in enumerate(byte_ranges.items()):\n",
        "\n",
        "    if i == 0:\n",
        "      # If we are working on the first item, overwrite the existing file.\n",
        "      curl = f'curl -s --range {byteRange} {remote_url} > {local_file}'\n",
        "      #print(\">>  Adding curl command: \" + curl)\n",
        "    else:\n",
        "      # If we are working on not the first item, append the existing file.\n",
        "      curl = f'curl -s --range {byteRange} {remote_url} >> {local_file}'\n",
        "      #print(\"Adding curl command: \" + curl)\n",
        "    #print('>>  Parsing line: ' + line)\n",
        "    try:\n",
        "      num, byte, date, var, level, forecast, _ = line.split(':')\n",
        "    except:\n",
        "      pass\n",
        "      #print(\">>>  Can't get num/byte/etc from this line, so skipping...\")\n",
        "\n",
        "    #print(f'  Downloading GRIB line [{num:>3}]: variable={var}, level={level}, forecast={forecast}')\n",
        "    #print(f'  Downloading GRIB line: variable={var}, level={level}, forecast={forecast}')\n",
        "    #print(\"Running the curl command...\")\n",
        "    os.system(curl)\n",
        "\n",
        "  if os.path.exists(local_file):\n",
        "    print(f'      ✅ Success! Searched for [{search_string}] and got [{len(byte_ranges)}] GRIB fields and saved as {local_file}')\n",
        "    return local_file\n",
        "  else:\n",
        "    print(print(f'      ❌ Unsuccessful! Searched for [{search_string}] and did not find anything!'))\n",
        "\n",
        "def project_hrap(lon, lat, s4x, s4y):\n",
        "  lon = float(lon)\n",
        "  lat = float(lat)\n",
        "\n",
        "  globe = ccrs.Globe(semimajor_axis=6371200)\n",
        "  hrap_ccrs = proj = ccrs.Stereographic(central_latitude=90.0,\n",
        "                          central_longitude=255.0,\n",
        "                          true_scale_latitude=60.0, globe=globe)\n",
        "  latlon_ccrs = ccrs.PlateCarree()\n",
        "  hrap_coords = hrap_ccrs.transform_point(lon,lat,src_crs=latlon_ccrs)\n",
        "  hrap_idx = ll_to_index(s4x, s4y, hrap_coords[0], hrap_coords[1])\n",
        "\n",
        "  return hrap_idx\n",
        "\n",
        "def nohrsc_ll2ij(lon,lat,gridlons,gridlats):\n",
        "  #for a lat/lon grid\n",
        "  lon = float(lon)\n",
        "  lat = float(lat)\n",
        "  lonidx=(np.abs(lon-gridlons)).argmin()\n",
        "  latidx=(np.abs(lat-gridlats)).argmin()\n",
        "  return(latidx,lonidx)\n",
        "\n",
        "def get_stageiv():\n",
        "  siv_url = \"https://water.weather.gov/precip/downloads/\"+nbm_valid.strftime('%Y')+\"/\"+nbm_valid.strftime('%m')+\"/\"+nbm_valid.strftime('%d')+\"/nws_precip_1day_\"+nbm_valid.strftime('%Y%m%d')+\"_conus.nc\"\n",
        "  data = urlopen(siv_url).read()\n",
        "  nc = Dataset('data', memory=data)\n",
        "  stageIV = nc.variables['observation']\n",
        "  s4x = nc.variables['x']\n",
        "  s4y = nc.variables['y']\n",
        "  return stageIV, s4x, s4y\n",
        "\n",
        "def get_nohrsc():\n",
        "  nohrsc_url = \"https://www.nohrsc.noaa.gov/snowfall_v2/data/\"+nbm_valid.strftime('%Y%m')+\"/sfav2_CONUS_24h_\"+nbm_valid.strftime('%Y%m%d%H')+\".nc\"\n",
        "  data = urlopen(nohrsc_url).read()\n",
        "\n",
        "  nc = Dataset('data',memory=data)\n",
        "  snow=np.asarray(nc.variables['Data']) #make lon by lat array (original lat by lon)\n",
        "  snowlat = np.asarray(nc.variables['lat'])\n",
        "  snowlon = np.asarray(nc.variables['lon'])\n",
        "  return snow,snowlon,snowlat"
      ],
      "metadata": {
        "id": "oEUmn61FC-k7"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download and Read Obs\n",
        "print('Getting obs...')\n",
        "obs = {}\n",
        "if os.path.exists(\"obs\"):\n",
        "  pass\n",
        "else:\n",
        "  os.mkdir(\"obs\")\n",
        "\n",
        "synoptic_token = \"62e9269f0a164da1b2415ddcf8f4f29e\"\n",
        "statistics_api = \"https://api.synopticlabs.org/v2/stations/statistics?\"\n",
        "precipitation_api = \"https://api.synopticdata.com/v2/stations/precipitation?\"\n",
        "metadata_api = \"https://api.synopticdata.com/v2/stations/metadata?\"\n",
        "nearest_api = \"https://api.synopticdata.com/v2/stations/nearesttime?\"\n",
        "\n",
        "# Setup a dictionary for translating a form selection into a something we can pass to mesowest API\n",
        "network_dict = {\"NWS+RAWS+HADS\":\"&network=1,2,106\",\"NWS+RAWS\":\"&network=1,2\", \"NWS\":\"&network=1\", \"RAWS\": \"&network=2\", \"ALL\":\"\"} #, \"CUSTOM\": \"&network=\"+network_input, \"LIST\": \"&stid=\"+network_input}\n",
        "network_string = network_dict[network_selection]\n",
        "api_token=\"&token=\"+synoptic_token\n",
        "\n",
        "for region in region_list:\n",
        "  print(\"   > Grabbing obs for: \", region)\n",
        "  station_query=\"&cwa=\"+cwa_list(region)\n",
        "  json_name = \"obs/Obs_\"+element+\"_\"+nbm_valid.strftime('%Y%m%d%H')+\"_\"+region+\".json\"\n",
        "  if (nbm_valid <= current_datetime):\n",
        "    if element == \"mint\" or element == \"maxt\":\n",
        "      nbm_start=nbm_valid - timedelta(hours=18)\n",
        "      vars_query = \"&vars=air_temp\"\n",
        "      start_query = \"&start=\"+nbm_start.strftime('%Y%m%d%H%M')\n",
        "      end_query = \"&end=\"+nbm_valid.strftime('%Y%m%d%H%M')\n",
        "      if element == \"mint\":\n",
        "        ob_stat=\"minimum\"\n",
        "      else:\n",
        "        ob_stat=\"maximum\"\n",
        "      stat_type = \"&type=\"+ob_stat\n",
        "      network_query = network_string\n",
        "      api_extras = \"&units=temp%7Cf&within=1440&status=active\"\n",
        "      obs_url = statistics_api + api_token + station_query + vars_query + start_query + end_query + stat_type + network_query + api_extras\n",
        "    elif element == \"maxwind\":\n",
        "      nbm_start = nbm_valid - timedelta (days=1)\n",
        "      vars_query = \"&vars=wind_speed\"\n",
        "      start_query = \"&start=\"+nbm_start.strftime('%Y%m%d%H%M')\n",
        "      end_query = \"&end=\"+nbm_valid.strftime('%Y%m%d%H%M')\n",
        "      stat_type = \"&type=maximum\"\n",
        "      network_query = network_string\n",
        "      obs_url = statistics_api + api_token + station_query + vars_query + start_query + end_query + stat_type + network_query\n",
        "    elif element == \"qpf\":\n",
        "      if use_stageiv:\n",
        "        api_extras = \"&fields=status,latitude,longitude,name,elevation\"\n",
        "        network_query = network_string\n",
        "        obs_url = metadata_api + api_token + station_query + network_query + api_extras\n",
        "        stageIV, s4xs, s4ys = get_stageiv()\n",
        "        s4xs, s4ys = np.meshgrid(s4xs, s4ys)\n",
        "      else:\n",
        "        nbm_start = nbm_valid - timedelta(days=1)\n",
        "        api_extras = \"&fields=status,latitude,longitude,name,elevation&obtimezone=utc\"\n",
        "        network_query = network_string\n",
        "        vars_query = \"&pmode=totals\"\n",
        "        units_query = \"&units=precip|in\"\n",
        "        start_query = \"&start=\"+nbm_start.strftime('%Y%m%d%H%M')\n",
        "        end_query = \"&end=\"+nbm_valid.strftime('%Y%m%d%H%M')\n",
        "        obs_url = precipitation_api + api_token + station_query + network_query + vars_query + start_query + end_query + units_query + api_extras\n",
        "    elif element == \"snow\":\n",
        "      if use_nohrsc:\n",
        "        api_extras = \"&fields=status,latitude,longitude,name,elevation\"\n",
        "        network_query = network_string\n",
        "        obs_url = metadata_api + api_token + station_query + network_query + api_extras\n",
        "        snow,snowlon,snowlat = get_nohrsc()\n",
        "        snowlons,snowlats = np.meshgrid(snowlon,snowlat)\n",
        "      else:\n",
        "        nbm_start = nbm_valid - timedelta(days=1)\n",
        "        api_extras = \"&fields=status,latitude,longitude,name,elevation&obtimezone=utc\"\n",
        "        network_query = network_string\n",
        "        vars_query = \"&pmode=totals\"\n",
        "        units_query = \"&units=precip|in\"\n",
        "        start_query = \"&start=\"+nbm_start.strftime('%Y%m%d%H%M')\n",
        "        end_query = \"&end=\"+nbm_valid.strftime('%Y%m%d%H%M')\n",
        "        obs_url = precipitation_api + api_token + station_query + network_query + vars_query + start_query + end_query + units_query + api_extras\n",
        "    else: # element == \"temp\" or element == \"dwpt\":\n",
        "      api_extras=\"&fields=status,latitude,longitude,name,elevation&obtimezone=utc\"\n",
        "      network_query = network_string\n",
        "      time_query=\"&attime=\"+nbm_valid.strftime('%Y%m%d%H%M')+\"&within=30\"\n",
        "      if element == \"temp\":\n",
        "        vars_query=\"&vars=air_temp\"\n",
        "      elif element == \"dwpt\":\n",
        "        vars_query=\"&vars=dew_point_temperature\"\n",
        "      elif element == \"wspd\":\n",
        "        vars_query=\"&vars=wind_speed\"\n",
        "      elif element == \"gust\":\n",
        "        vars_query=\"&vars=wind_gust\"\n",
        "      elif element == \"vis\":\n",
        "        vars_query=\"&vars=visibility\"\n",
        "      elif element == \"ceil\":\n",
        "        vars_query=\"&vars=ceiling\"\n",
        "      elif element == \"qpf01\":\n",
        "        vars_query=\"&vars=precip_accum_one_hour\"\n",
        "      elif element == \"qpf03\":\n",
        "        vars_query=\"&vars=precip_accum_three_hour\"\n",
        "      elif element == \"qpf06\":\n",
        "        vars_query = \"&vars=precip_accum_six_hour\"\n",
        "      elif element == \"qpf24\":\n",
        "        vars_query = \"&vars=precip_accum_24_hour\"\n",
        "      obs_url = nearest_api + api_token + station_query + vars_query + time_query + api_extras\n",
        "    print(\"Obs url: \" + obs_url)\n",
        "    if os.path.exists(json_name):\n",
        "      print (\"Skipping download since JSON file already exists\")\n",
        "      pass\n",
        "    else:\n",
        "      urlretrieve(obs_url, json_name)\n",
        "    #now read the file\n",
        "    if os.path.exists(json_name):\n",
        "      with open(json_name) as json_file:\n",
        "        obs_json = json.load(json_file)\n",
        "        obs_lats = []\n",
        "        obs_lons = []\n",
        "        obs_value = []\n",
        "        obs_elev = []\n",
        "        obs_stid = []\n",
        "        obs_name = []\n",
        "        for stn in obs_json[\"STATION\"]:\n",
        "          # print(stn.encode('utf-8'))\n",
        "          if stn[\"STID\"] is None:\n",
        "            stid = \"N0N3\"\n",
        "          else:\n",
        "            stid = stn[\"STID\"]\n",
        "            #print(f'Processing {region} station {stid}')\n",
        "            name = stn[\"NAME\"]\n",
        "            if stn[\"ELEVATION\"] and stn[\"ELEVATION\"] is not None:\n",
        "              elev = stn[\"ELEVATION\"]\n",
        "            else:\n",
        "              elev = -999\n",
        "            lat = stn[\"LATITUDE\"]\n",
        "            lon = stn[\"LONGITUDE\"]\n",
        "            if element == \"mint\" or element==\"maxt\":\n",
        "              if 'air_temp_set_1' in stn['STATISTICS'] and stn['STATISTICS']['air_temp_set_1']:\n",
        "                if ob_stat in stn['STATISTICS']['air_temp_set_1']: # and float(stn[\"LATITUDE\"]) != 0. and float(stn[\"LONGITUDE\"]) != 0.:\n",
        "                  stat = stn['STATISTICS']['air_temp_set_1'][ob_stat]\n",
        "                  obs_stid.append(str(stid))\n",
        "                  obs_name.append(str(name))\n",
        "                  obs_elev.append(float(elev))\n",
        "                  obs_lats.append(float(lat))\n",
        "                  obs_lons.append(float(lon))\n",
        "                  obs_value.append(C_to_F(float(stat)))\n",
        "            elif element == \"maxwind\":\n",
        "                if 'wind_speed_set_1' in stn['STATISTICS'] and stn['STATISTICS']['wind_speed_set_1']:\n",
        "                  if ob_stat in stn['STATISTICS']['wind_speed_set_1']: # and float(stn[\"LATITUDE\"]) != 0.:\n",
        "                    stat = stn['STATISTICS']['wind_speed_set_1'][ob_stat]\n",
        "                    obs_stid.append(str(stid))\n",
        "                    obs_name.append(str(name))\n",
        "                    obs_elev.append(float(elev))\n",
        "                    obs_lats.append(float(lat))\n",
        "                    obs_lons.append(float(lon))\n",
        "                    obs_value.append(mps_to_kts(float(stat)))\n",
        "            elif (element == \"qpf\"):\n",
        "                if (stn[\"STATUS\"] == \"ACTIVE\"): # and float(stn[\"LATITUDE\"]) < 50.924 and float(stn[\"LATITUDE\"]) > 23.377 and float(stn[\"LONGITUDE\"]) > -125.650 and float(stn[\"LONGITUDE\"]) < -66.008:\n",
        "                  obs_stid.append(str(stid))\n",
        "                  obs_name.append(str(name))\n",
        "                  obs_elev.append(float(elev))\n",
        "                  obs_lats.append(float(lat))\n",
        "                  obs_lons.append(float(lon))\n",
        "                  if use_stageiv:\n",
        "                    coords = project_hrap(lon, lat, s4xs, s4ys)\n",
        "                    siv_value = float(stageIV[coords])\n",
        "                    if (siv_value >= 0.01):\n",
        "                      obs_value.append(siv_value)\n",
        "                    else:\n",
        "                      obs_value.append(0.0)\n",
        "                  else:\n",
        "                    if \"precipitation\" in stn[\"OBSERVATIONS\"]:\n",
        "                      if \"total\" in stn[\"OBSERVATIONS\"][\"precipitation\"][0]:\n",
        "                        ptotal = stn[\"OBSERVATIONS\"][\"precipitation\"][0][\"total\"]\n",
        "                        if ptotal >= 0.005:\n",
        "                          obs_value.append(ptotal)\n",
        "                        else:\n",
        "                          obs_value.append(0.0)\n",
        "                      else:\n",
        "                        obs_value.append(np.nan)\n",
        "                    else:\n",
        "                      obs_value.append(np.nan)\n",
        "            elif (element == \"snow\"):\n",
        "                if stn[\"STATUS\"] == \"ACTIVE\": # and float(stn[\"LATITUDE\"]) < 50.924)and float(stn[\"LATITUDE\"]) > 23.377 and float(stn[\"LONGITUDE\"]) > -125.650 and float(stn[\"LONGITUDE\"]) < -66.008:\n",
        "                    obs_stid.append(str(stid))\n",
        "                    obs_name.append(str(name))\n",
        "                    obs_elev.append(float(elev))\n",
        "                    obs_lats.append(float(lat))\n",
        "                    obs_lons.append(float(lon))\n",
        "                    if use_nohrsc:\n",
        "                      coords = nohrsc_ll2ij(lon,lat,snowlon,snowlat)\n",
        "                      nohrsc_value = meters_to_in(float(snow[coords]))\n",
        "                      if nohrsc_value >= 0.005:\n",
        "                        obs_value.append(nohrsc_value)\n",
        "                      elif nohrsc_value < 0.0:\n",
        "                        obs_value.append(np.nan)\n",
        "                      else:\n",
        "                        obs_value.append(0.0)\n",
        "                    else:\n",
        "                      raise Exception(\"Still not able to process individual snow obs!\")\n",
        "            elif (element == \"temp\"):\n",
        "              if stn[\"STATUS\"] == \"ACTIVE\":\n",
        "                if 'air_temp_value_1' in stn['OBSERVATIONS'] and stn['OBSERVATIONS']['air_temp_value_1']:\n",
        "                  value=stn['OBSERVATIONS']['air_temp_value_1']['value']\n",
        "                  obs_stid.append(str(stid))\n",
        "                  obs_name.append(str(name))\n",
        "                  obs_elev.append(float(elev))\n",
        "                  obs_lats.append(float(lat))\n",
        "                  obs_lons.append(float(lon))\n",
        "                  obs_value.append(C_to_F(float(value)))\n",
        "            elif element == \"wspd\":\n",
        "              if stn[\"STATUS\"] == \"ACTIVE\":\n",
        "                if 'wind_speed_value_1' in stn['OBSERVATIONS'] and stn['OBSERVATIONS']['wind_speed_value_1']:\n",
        "                  value=stn['OBSERVATIONS']['wind_speed_value_1']['value']\n",
        "                  obs_stid.append(str(stid))\n",
        "                  obs_name.append(str(name))\n",
        "                  obs_elev.append(float(elev))\n",
        "                  obs_lats.append(float(lat))\n",
        "                  obs_lons.append(float(lon))\n",
        "                  obs_value.append(mps_to_kts(float(value)))\n",
        "            elif element == \"gust\":\n",
        "              if stn[\"STATUS\"] == \"ACTIVE\":\n",
        "                if 'wind_gust_value_1' in stn['OBSERVATIONS'] and stn['OBSERVATIONS']['wind_gust_value_1']:\n",
        "                  value=stn['OBSERVATIONS']['wind_gust_value_1']['value']\n",
        "                  obs_stid.append(str(stid))\n",
        "                  obs_name.append(str(name))\n",
        "                  obs_elev.append(float(elev))\n",
        "                  obs_lats.append(float(lat))\n",
        "                  obs_lons.append(float(lon))\n",
        "                  obs_value.append(mps_to_kts(float(value)))\n",
        "            elif element == \"dwpt\":\n",
        "              if stn[\"STATUS\"] == \"ACTIVE\":\n",
        "                if 'dew_point_value_1' in stn['OBSERVATIONS'] and stn['OBSERVATIONS']['dew_point_value_1']:\n",
        "                  value=stn['OBSERVATIONS']['dew_point_value_1']['value']\n",
        "                  obs_stid.append(str(stid))\n",
        "                  obs_name.append(str(name))\n",
        "                  obs_elev.append(float(elev))\n",
        "                  obs_lats.append(float(lat))\n",
        "                  obs_lons.append(float(lon))\n",
        "                  obs_value.append(C_to_F(float(value)))\n",
        "            elif element == \"vis\":\n",
        "              if stn[\"STATUS\"] == \"ACTIVE\":\n",
        "                if 'visibility_value_1' in stn['OBSERVATIONS'] and stn['OBSERVATIONS']['visiblity_value_1']:\n",
        "                  value=stn['OBSERVATIONS']['visibility_value_1']['value']\n",
        "                  obs_stid.append(str(stid))\n",
        "                  obs_name.append(str(name))\n",
        "                  obs_elev.append(float(elev))\n",
        "                  obs_lats.append(float(lat))\n",
        "                  obs_lons.append(float(lon))\n",
        "                  obs_value.append(miles_to_meters(float(value)))\n",
        "            elif element == \"ceil\":\n",
        "              if stn['STATUS'] == \"ACTIVE\":\n",
        "                if 'ceiling_value_1' in stn['OBSERVATIONS'] and stn['OBSERVATIONS']['ceiling_value_1']:\n",
        "                  value=stn['OBSERVATIONS']['ceiling_value_1']['value']\n",
        "                  obs_stid.append(str(stid))\n",
        "                  obs_name.append(str(name))\n",
        "                  obs_elev.append(float(elev))\n",
        "                  obs_lats.append(float(lat))\n",
        "                  obs_lons.append(float(lon))\n",
        "                  obs_value.append(float(value))\n",
        "      csv_name = \"obs_\"+element+\"_\"+region+\"_\"+nbm_valid.strftime(\"%Y%m%d%H\")+\".csv\"\n",
        "      obs[region] = pd.DataFrame()\n",
        "      obs[region][\"stid\"] = obs_stid\n",
        "      obs[region][\"name\"] = obs_name\n",
        "      obs[region][\"elevation\"] = obs_elev\n",
        "      obs[region][\"lat\"] = obs_lats\n",
        "      obs[region][\"lon\"] = obs_lons\n",
        "      obs[region][\"ob_\"+element] = obs_value\n",
        "      obs[region].dropna(inplace=True)\n",
        "      obs[region].to_csv(csv_name)\n",
        "    else:\n",
        "      raise Exception (\"Can't find obs file after download attempt: \" + json_name)\n",
        "  else:\n",
        "    raise Exception (\"Valid time is in the future: Cannot retrieve obs!\")"
      ],
      "metadata": {
        "id": "OYM_ZWGkHulm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbd200d8-b8bc-47b7-bc8c-9fa8fd579dc7"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting obs...\n",
            "   > Grabbing obs for:  LWX\n",
            "Obs url: https://api.synopticdata.com/v2/stations/nearesttime?&token=62e9269f0a164da1b2415ddcf8f4f29e&cwa=LWX&vars=air_temp&attime=202312191800&within=30&fields=status,latitude,longitude,name,elevation&obtimezone=utc\n",
            "Skipping download since JSON file already exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download NBM Grids\n",
        "if \"AR\" in region_list or \"AJK\" in region_list or \"ARH\" in region_list or \"AFC\" in region_list:\n",
        "  rg=\"ak\"\n",
        "elif \"HFO\" in region_list:\n",
        "  rg=\"hi\"\n",
        "elif \"SJU\" in region_list:\n",
        "  rg=\"pr\"\n",
        "else:\n",
        "  rg=\"co\"\n",
        "\n",
        "nbm_init_filen = nbm_init.strftime('%Y%m%d') + \"_\" + nbm_init.strftime('%H')\n",
        "nbm_url_base = \"https://noaa-nbm-grib2-pds.s3.amazonaws.com/blend.\"+nbm_init.strftime('%Y%m%d') +\"/\"+nbm_init.strftime('%H')+\"/\"\n",
        "\n",
        "core_vars = [\"maxt\",\"mint\",\"temp\",\"dwpt\",\"ceil\",\"vis\",\"gust\",\"wspd\"]\n",
        "#if (element == \"qpf\"):\n",
        "#  detr_file = f'blend.t{int(nbm_init_hour):02}z.qmd.f{int(lookback_hours):03}.{rg}.grib2'\n",
        "#  detr_file_subset = f'blend.t{int(nbm_init_hour):02}z.qmd.{nbm_init_filen}.f{int(nbm_qmd_forecasthour):03}.{rg}.{element}_subset.grib2'\n",
        "#  detr_url = nbm_url_base+\"qmd/\"+detr_file\n",
        "#\n",
        "#elif any(te in element for te in core_vars):\n",
        "detr_file = f\"blend.t{int(nbm_init.strftime('%H')):02}z.core.f{int(lookback_hours):03}.{rg}.grib2\"\n",
        "#detr_file_subset = f\"blend.t{int(nbm_init.strftime('%H')):02}z.core.{nbm_init_filen}.f{int(lookback_hours):03}.{rg}.{element}_subset.grib2\"\n",
        "detr_url = nbm_url_base+\"core/\"+detr_file\n",
        "\n",
        "if os.path.exists(\"nbm/\"+detr_file):\n",
        "  print(\"  > NBM Deterministic file already downloaded\")\n",
        "else:\n",
        "  print(\"  > Getting NBM core file\")\n",
        "  if os.path.exists(\"nbm\"):\n",
        "    pass\n",
        "  else:\n",
        "    os.mkdir(\"nbm\")\n",
        "  os.system(f' curl -s {detr_url} > nbm/{detr_file}')\n",
        "nbmd = pygrib.open(\"nbm/\"+detr_file)\n",
        "if element == \"temp\":\n",
        "  deterministic = nbmd.select(name=\"2 metre temperature\",typeOfLevel=\"heightAboveGround\",level=2,forecastTime=lookback_hours)[0]\n",
        "elif element == \"dwpt\":\n",
        "  deterministic = nbmd.select(name=\"2 metre dew point\",typeOfLevel=\"heightAboveGround\",level=2,forecastTime=lookback_hours)[0]\n",
        "elif element == \"wspd\":\n",
        "  determinisitc = nbmd.select(name=\"10 metre wind speed\",typeOfLevel=\"heightAboveGround\",level=10,forecastTime=lookback_hours)[0]\n",
        "elif element == \"gust\":\n",
        "  deterministic = nbmd.select(name=\"10 metre wind speed (gust)\",typeOfLevel=\"heightAboveGround\",level=10,forecastTime=lookback_hours)[0]\n",
        "elif element == \"ceil\":\n",
        "  deterministic = nbmd.select(name=\"Ceiling\",typeOfLevel=\"cloudCeiling\",forecastTime=lookback_hours)[0]\n",
        "  if deterministic.is_missing(probabilityType):\n",
        "    pass\n",
        "  else:\n",
        "    raise Exception (\"Probabilties found when deterministic expected for ceiling\")\n",
        "elif element == \"vis\":\n",
        "  determinisitc = nbmd.select(name=\"Visibility\",typeOfLevel=\"surface\",forecastTime=lookback_hours)[0]\n",
        "  if determinisitc.is_missing(probabilityType):\n",
        "    pass\n",
        "  else:\n",
        "    raise Exception (\"Probabilities found when determinisitc expected for visiblity\")\n",
        "elif element == \"qpf01\":\n",
        "  determinisitc = nbmd.select(name=\"Total Precipitation\",typeOfLevel=\"surface\",typeOfStatisticalProcessing=1,lengthOfTimeRange=1)[0]\n",
        "elif element == \"qpf06\":\n",
        "  determinisitc = nbmd.select(name=\"Total Precipitation\",typeOfLevel=\"surface\",typeOfStatisticalProcessing=1,lengthOfTimeRange=6)[0]\n",
        "elif element == \"qpf12\":\n",
        "  determinisitc = nbmd.select(name=\"Total Precipitation\",typeOfLevel=\"surface\",typeOfStatisticalProcessing=1,lengthOfTimeRange=12)[0]\n",
        "\n",
        "if element in [\"temp\",\"dwpt\",\"maxt\",\"mint\"]:\n",
        "  deterministic_values=K_to_F(deterministic.values)\n",
        "elif element in [\"qpf01\",\"qpf06\",\"qpf12\",\"qpf24\"]:\n",
        "  deterministic_values=mm_to_in(deterministic.values)\n",
        "elif element in [\"wspd\",\"gust\",\"maxspeed\",\"maxgust\"]:\n",
        "  deterministic_values=mps_to_kts(deterministic.values)\n",
        "else:\n",
        "  deterministic_values=deterministic.values\n",
        "nbmlats, nbmlons = deterministic.latlons()\n",
        "nbmd.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joLEVW3tlrKZ",
        "outputId": "e6ac15eb-e937-416c-bb71-a4a8febac28e"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  > NBM Deterministic file already downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Interpolate Grid to Obs\n",
        "\n",
        "for region in region_list:\n",
        "  point_lats = obs[region][\"lat\"].values\n",
        "  point_lons = obs[region][\"lon\"].values\n",
        "  detr_values = []\n",
        "  nbm_fidx = []\n",
        "  for i in range(0,len(point_lats)):\n",
        "    coords = ll_to_index(nbmlons,nbmlats,point_lons[i],point_lats[i])\n",
        "    fcst_value = deterministic_values[coords]\n",
        "    nbm_fidx.append(coords)\n",
        "    detr_values.append(fcst_value)\n",
        "  obs[region][\"NBM_fidx\"] = nbm_fidx\n",
        "  obs[region][\"Forecast\"] = detr_values\n",
        "  obs[region][\"O-F\"] = obs[region][\"ob_\"+element] - obs[region][\"Forecast\"]\n",
        "  csv_name=f'obs_and_fcsts.{element}.{nbm_init.strftime(\"%Y%m%d\")}.t{nbm_init.strftime(\"%H\")}z.f{int(lookback_hours):03}.{region}.csv'\n",
        "  obs[region].to_csv(csv_name)\n",
        "  print(f'   > Created and saved {csv_name}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOtULGdEN8O8",
        "outputId": "004a9f47-4a20-40fe-eb3a-96a87fd4ae64"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   > Created and saved obs_and_fcsts.temp.20231217.t06z.f060.LWX.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Make Statistics\n",
        "\n",
        "oblist=obs[region][\"ob_\"+element]\n",
        "fcstlist=obs[region][\"Forecast\"]\n",
        "\n",
        "RMSE=mean_squared_error(oblist,fcstlist)\n",
        "MAE=mean_absolute_error(oblist,fcstlist)\n",
        "BIAS=(np.mean(oblist)-np.mean(fcstlist))/(len(obs[region].index))\n",
        "VARIANCE=explained_variance_score(oblist,fcstlist)\n",
        "\n",
        "print(f'RMSE: {RMSE}')\n",
        "print(f'MAE: {MAE}')\n",
        "print(f'BIAS: {BIAS}')\n",
        "print(f'VARIANCE: {VARIANCE}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BJnN1Ce0SWk",
        "outputId": "cf021e43-a441-4161-f84b-b826e94739a8"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 2.309527889341495\n",
            "MAE: 1.2577112409607532\n",
            "BIAS: -0.001470608617015213\n",
            "VARIANCE: 0.844853692731495\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generate Plot\n",
        "\n",
        "matplotlib.rc('axes',facecolor=background_color,edgecolor=text_color)\n",
        "fig_valid_date=nbm_valid.strftime(\"%HZ %m-%d-%Y\")\n",
        "fcst_date=nbm_init.strftime(\"%HZ %m-%d%-Y\")\n",
        "\n",
        "compare_var=\"O-F\"\n",
        "\n",
        "#set colors/ranges by variable\n",
        "if element in [\"temp\",\"dwpt\",\"maxt\",\"mint\"]:\n",
        "  cmap=get_cmap(\"bwr\")\n",
        "  vmin=-10.0\n",
        "  vmax=10.0\n",
        "elif element in [\"qpf01\",\"qpf06\",\"qpf12\",\"qpf24\"]:\n",
        "  cmap=get_cmap(\"BrBG\")\n",
        "  vmin=-2.0\n",
        "  vmax=2.0\n",
        "elif element in [\"ceil\",\"vis\"]:\n",
        "  cmap=get_cmap(\"RdYlGn\")\n",
        "  vmin=-5000.0\n",
        "  vmax=5000.0\n",
        "else:\n",
        "  raise Exception (\"Notebook not configured for this variable yet: \" + element)\n",
        "\n",
        "def flip(items, ncol):\n",
        "    return itertools.chain(*[items[i::ncol] for i in range(ncol)])\n",
        "\n",
        "if (region_selection == \"WR\"):\n",
        "      west = -126.917\n",
        "      south = 30.586\n",
        "      east = -102.740\n",
        "      north = 49.755\n",
        "      width, height = (16,9)\n",
        "      width_ratios = [9,8]\n",
        "      lloc = \"lower right\"\n",
        "elif (region_selection == \"CR\"):\n",
        "      west = -111.534\n",
        "      south = 33.295\n",
        "      east = -81.723\n",
        "      north = 49.755\n",
        "      width, height = (16,7)\n",
        "      width_ratios = [9,7]\n",
        "      lloc = \"lower center\"\n",
        "elif (region_selection == \"ER\"):\n",
        "      west = -86.129\n",
        "      south = 31.223\n",
        "      east = -66.465\n",
        "      north = 47.676\n",
        "      width, height = (16,7.25)\n",
        "      width_ratios = [6.9,9.5]\n",
        "      lloc = \"lower right\"\n",
        "elif (region_selection == \"SR\"):\n",
        "    west = -109.758\n",
        "    south = 23.313\n",
        "    east = -79.247\n",
        "    north = 36.899\n",
        "    width, height = (16,5.6)\n",
        "    width_ratios = [10,6]\n",
        "    lloc = \"lower center\"\n",
        "else: #if (region_selection == \"CWA\"):\n",
        "    west = np.min(obs[region][\"lon\"]) - 0.5\n",
        "    south = np.min(obs[region][\"lat\"]) - 0.5\n",
        "    east = np.max(obs[region][\"lon\"]) + 1.0\n",
        "    north = np.max(obs[region][\"lat\"]) + 0.5\n",
        "    width, height = (16,9)\n",
        "    ratioxy = 16./9.\n",
        "    width_ratios = [ratioxy, 1]\n",
        "    lloc = \"center right\"\n",
        "\n",
        "\n",
        "#width, height = (16,9)\n",
        "fig = plt.figure(constrained_layout=True, figsize=(width,height), facecolor=background_color, frameon=True, dpi=150)\n",
        "if (region_selection == \"CWA\"):\n",
        "  dataframeid = cwa_id\n",
        "else:\n",
        "  dataframeid = region_selection\n",
        "#ratioxy = 16./9.\n",
        "#width_ratios = [ratioxy, 1]\n",
        "grid = fig.add_gridspec(1,2, hspace=0.2, width_ratios=width_ratios, height_ratios = [1], wspace=0.2)\n",
        "ax1 = fig.add_subplot(grid[0,0], projection=ccrs.Mercator())\n",
        "#ax1 = fig.add_subplot(grid[0,0], projection=ccrs.LambertConformal(central_latitude=25, central_longitude=265, standard_parallels=(25,25)))\n",
        "ax2 = fig.add_subplot(grid[0,1], )\n",
        "\n",
        "lats = obs[dataframeid][\"lat\"].values\n",
        "lons = obs[dataframeid][\"lon\"].values\n",
        "point_data = obs[dataframeid][compare_var].values\n",
        "mean = obs[dataframeid][compare_var].mean()\n",
        "median = obs[dataframeid][compare_var].median()\n",
        "#mode = obs[dataframeid][compare_var].mode().values[0]\n",
        "proj = ccrs.PlateCarree()\n",
        "numcols=(abs(np.amax(point_data) - np.amin(point_data))//10) + 1\n",
        "\n",
        "ax1.set_anchor('N')\n",
        "ax1.set_facecolor(background_color)\n",
        "ax1.set_extent([west, east, south, north], crs=proj)\n",
        "#ax1.add_feature(cfeature.LAND, edgecolor='none', facecolor='#414143', zorder=-1)\n",
        "ax1.add_feature(cfeature.OCEAN, edgecolor='none', facecolor=map_water_color, zorder=-2)\n",
        "ax1.add_feature(cfeature.NaturalEarthFeature('physical', 'land', '50m', edgecolor='none', facecolor=map_land_color, zorder=-1))\n",
        "#ax1.add_feature(cfeature.LAKES, edgecolor='none', facecolor='#272727', zorder=0)\n",
        "ax1.add_feature(cfeature.NaturalEarthFeature('physical', 'lakes', '10m', edgecolor='none', facecolor=map_water_color, zorder=0))\n",
        "ax1.add_feature(cfeature.BORDERS, edgecolor=map_border_color, facecolor='none', linewidth=2, zorder=2)\n",
        "#ax1.add_feature(cfeature.NaturalEarthFeature('cultural', 'countries', '50m', edgecolor=map_border_color, facecolor='none', linewidth=2, zorder=2))\n",
        "ax1.add_feature(cfeature.NaturalEarthFeature('cultural', 'admin_1_states_provinces_lines', '50m', edgecolor=map_border_color, facecolor='none', linewidth=1, zorder=5))\n",
        "#ax1.add_feature(cfeature.NaturalEarthFeature('cultural', 'admin_1_states_provinces_lines', '50m', edgecolor=map_border, facecolor='none', linewidth=1, zorder=5))\n",
        "#cx.add_basemap(ax1, source='https://server.arcgisonline.com/ArcGIS/rest/services/Canvas/World_Dark_Gray_Base/MapServer/tile/{z}/{y}/{x}', attribution=False)\n",
        "scatter = ax1.scatter(lons, lats, c= point_data, cmap=cmap, s=45, transform=proj, zorder=2, vmin=vmin, vmax=vmax)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "P1S74YpU3zAt",
        "outputId": "8e8d12a4-f7b2-4257-ee09-4c013bdd0a15"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-14bf3a91d020>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#@title Generate Plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfacecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackground_color\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medgecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_color\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mfig_valid_date\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnbm_valid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%HZ %m-%d-%Y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfcst_date\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnbm_init\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%HZ %m-%d%-Y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'background_color' is not defined"
          ]
        }
      ]
    }
  ]
}