{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMv9ZXcxUr6nqgXcWPojdwc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StevenLevine-NOAA/NBM-Verif/blob/notebooks/Probs_and_Obs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5p8gLFDP7eUY",
        "outputId": "3dbe49da-ff49-4c64-c2c8-1f49ef858bd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â¬ Downloading https://github.com/conda-forge/miniforge/releases/download/23.1.0-1/Mambaforge-23.1.0-1-Linux-x86_64.sh...\n",
            "ðŸ“¦ Installing...\n",
            "ðŸ“Œ Adjusting configuration...\n",
            "ðŸ©¹ Patching environment...\n",
            "â² Done in 0:00:17\n",
            "ðŸ” Restarting kernel...\n"
          ]
        }
      ],
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Initialize Notebook Part 2\n",
        "#!mamba install -q -c conda-forge cartopy contextily pyproj pyepsg pygrib netCDF4\n",
        "!pip install cartopy contextily pyproj pyepsg pygrib netCDF4\n",
        "import numpy as np\n",
        "from scipy.interpolate import CubicSpline as cs, UnivariateSpline as us\n",
        "import pandas as pd\n",
        "from urllib.request import urlretrieve, urlopen\n",
        "import requests\n",
        "from datetime import datetime, timedelta\n",
        "import json\n",
        "from netCDF4 import Dataset\n",
        "import pygrib\n",
        "import pyproj\n",
        "from pyproj import Proj, transform\n",
        "import os, re, traceback\n",
        "\n",
        "import matplotlib\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "#from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "import matplotlib.patches as mpatches\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.axes as maxes\n",
        "import matplotlib.patheffects as PathEffects\n",
        "from matplotlib.path import Path\n",
        "from matplotlib.textpath import TextToPath\n",
        "import matplotlib.gridspec as gridspec\n",
        "from matplotlib.font_manager import FontProperties\n",
        "matplotlib.rcParams['font.sans-serif'] = 'Liberation Sans'\n",
        "matplotlib.rcParams['font.family'] = \"sans-serif\"\n",
        "from matplotlib.cm import get_cmap\n",
        "import seaborn as sns\n",
        "\n",
        "from cartopy import crs as ccrs, feature as cfeature\n",
        "from cartopy.io.shapereader import Reader\n",
        "from cartopy.feature import ShapelyFeature\n",
        "import contextily as cx\n",
        "import itertools\n",
        "\n",
        "import zipfile\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2U6kbnHr7xYp",
        "outputId": "d8438e07-f88c-420d-c62a-a7df75829ec8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cartopy in /usr/local/lib/python3.10/site-packages (0.22.0)\n",
            "Requirement already satisfied: contextily in /usr/local/lib/python3.10/site-packages (1.5.0)\n",
            "Requirement already satisfied: pyproj in /usr/local/lib/python3.10/site-packages (3.6.1)\n",
            "Requirement already satisfied: pyepsg in /usr/local/lib/python3.10/site-packages (0.4.0)\n",
            "Requirement already satisfied: pygrib in /usr/local/lib/python3.10/site-packages (2.1.5)\n",
            "Requirement already satisfied: netCDF4 in /usr/local/lib/python3.10/site-packages (1.6.5)\n",
            "Requirement already satisfied: matplotlib>=3.4 in /usr/local/lib/python3.10/site-packages (from cartopy) (3.8.2)\n",
            "Requirement already satisfied: pyshp>=2.1 in /usr/local/lib/python3.10/site-packages (from cartopy) (2.3.1)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.10/site-packages (from cartopy) (23.2)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/site-packages (from cartopy) (1.26.4)\n",
            "Requirement already satisfied: shapely>=1.7 in /usr/local/lib/python3.10/site-packages (from cartopy) (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from contextily) (2.28.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/site-packages (from contextily) (10.2.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/site-packages (from contextily) (1.3.2)\n",
            "Requirement already satisfied: xyzservices in /usr/local/lib/python3.10/site-packages (from contextily) (2023.10.1)\n",
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.10/site-packages (from contextily) (1.3.9)\n",
            "Requirement already satisfied: mercantile in /usr/local/lib/python3.10/site-packages (from contextily) (1.2.1)\n",
            "Requirement already satisfied: geopy in /usr/local/lib/python3.10/site-packages (from contextily) (2.4.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/site-packages (from pyproj) (2022.12.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/site-packages (from pygrib) (65.6.3)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.10/site-packages (from netCDF4) (1.6.3)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib>=3.4->cartopy) (3.1.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib>=3.4->cartopy) (1.4.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/site-packages (from matplotlib>=3.4->cartopy) (2.8.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib>=3.4->cartopy) (4.48.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib>=3.4->cartopy) (0.12.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib>=3.4->cartopy) (1.2.0)\n",
            "Requirement already satisfied: geographiclib<3,>=1.52 in /usr/local/lib/python3.10/site-packages (from geopy->contextily) (2.0)\n",
            "Requirement already satisfied: click>=3.0 in /usr/local/lib/python3.10/site-packages (from mercantile->contextily) (8.1.7)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/site-packages (from rasterio->contextily) (23.2.0)\n",
            "Requirement already satisfied: snuggs>=1.4.1 in /usr/local/lib/python3.10/site-packages (from rasterio->contextily) (1.4.7)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/site-packages (from rasterio->contextily) (1.1.1)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.10/site-packages (from rasterio->contextily) (2.4.0)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/site-packages (from rasterio->contextily) (0.7.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->contextily) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests->contextily) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests->contextily) (3.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.4->cartopy) (1.16.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Select Options and Set Defaults\n",
        "\n",
        "element = \"mint\" #@param [\"maxt\", \"mint\",\"qpf\",\"maxwind\",\"snow\"]\n",
        "valid_date = \"2024-02-04\" #@param {type:\"date\"}\n",
        "qpf_valid_time = 12 #@param {type:\"slider\", min:0, max:18, step:6}\n",
        "use_stageiv = True #@param {type:\"boolean\"}\n",
        "use_nohrsc = True #@param {type:\"boolean\"}\n",
        "nbm_init_date = \"2024-02-01\" #@param {type:\"date\"}\n",
        "nbm_init_hour = 0 #@param {type:\"slider\", min:0, max:18, step:6}\n",
        "region_selection = \"ER\" #@param [\"WR\", \"SR\", \"CR\", \"ER\", \"AR\", \"CONUS\", \"CWA\"]\n",
        "cwa_id = \"OUN\" #@param {type:\"string\"}\n",
        "network_selection = \"NWS+RAWS\" #@param [\"NWS\", \"RAWS\", \"NWS+RAWS\", \"NWS+RAWS+HADS\", \"ALL\", \"CUSTOM\", \"LIST\"]\n",
        "cwa_outline = True #@param {type:\"boolean\"}\n",
        "county_outline = False #@param {type:\"boolean\"}\n",
        "export_csv = True #@param {type:\"boolean\"}\n",
        "#@markdown Light or dark theme plots?\n",
        "plot_style = \"dark\" #@param [\"light\", \"dark\"]\n",
        "\n",
        "if region_selection == \"CONUS\":\n",
        "  region_list = [\"WR\", \"CR\", \"SR\", \"ER\"]\n",
        "elif region_selection == \"CWA\":\n",
        "  region_list = [cwa_id]\n",
        "#elif region_selection == \"AR\":\n",
        "  #region_list=[\"AJK\",\"ARH\",\"AFC\"]\n",
        "else:\n",
        "  region_list = [region_selection]\n",
        "\n",
        "def cwa_list(input_region):\n",
        "  region_dict ={\"WR\":\"BYZ,BOI,LKN,EKA,FGZ,GGW,TFX,VEF,LOX,MFR,MTR,MSO,PDT,PSR,PIH,PQR,REV,STO,SLC,SGX,HNX,SEW,OTX,TWC\",\n",
        "              \"CR\":\"ABR,BIS,CYS,LOT,DVN,BOU,DMX,DTX,DDC,DLH,FGF,GLD,GJT,GRR,GRB,GID,IND,JKL,EAX,ARX,ILX,LMK,MQT,MKX,MPX,LBF,APX,IWX,OAX,PAH,PUB,UNR,RIW,FSD,SGF,LSX,TOP,ICT\",\n",
        "              \"ER\":\"ALY,LWX,BGM,BOX,BUF,BTV,CAR,CTP,RLX,CHS,ILN,CLE,CAE,GSP,MHX,OKX,PHI,PBZ,GYX,RAH,RNK,AKQ,ILM\",\n",
        "              \"SR\":\"ABQ,AMA,FFC,EWX,BMX,BRO,CRP,EPZ,FWD,HGX,HUN,JAN,JAX,KEY,MRX,LCH,LZK,LUB,MLB,MEG,MFL,MOB,MAF,OHX,LIX,OUN,SJT,SHV,TAE,TBW,TSA\",\n",
        "              \"AR\":\"AJK,ARH,AFC\"}\n",
        "  if (input_region in [\"WR\", \"CR\", \"SR\", \"ER\",\"AR\"]):\n",
        "    cwas_list = region_dict[input_region]\n",
        "  else:\n",
        "    cwas_list = input_region\n",
        "  return cwas_list\n",
        "\n",
        "nbm_init = datetime.strptime(nbm_init_date,'%Y-%m-%d') + timedelta(hours=int(nbm_init_hour))\n",
        "\n",
        "if element == \"maxt\":\n",
        "    nbm_core_valid_hour=\"00\"\n",
        "    nbm_qmd_valid_hour=\"06\"\n",
        "    valid_date_start = datetime.strptime(valid_date,'%Y-%m-%d')\n",
        "    valid_date_end = datetime.strptime(valid_date,'%Y-%m-%d') + timedelta(days=1)\n",
        "    obs_start_hour = \"1200\"\n",
        "    obs_end_hour = \"0600\"\n",
        "    ob_stat = \"maximum\"\n",
        "    valid_end_datetime = valid_date_end + timedelta(hours=(int(obs_end_hour)/100))\n",
        "    nbm_core_valid_end_datetime = valid_date_end + timedelta(hours=int(nbm_core_valid_hour))\n",
        "    nbm_qmd_valid_end_datetime = valid_date_end + timedelta(hours=int(nbm_qmd_valid_hour))\n",
        "    core_init = nbm_init + timedelta(hours = 7)\n",
        "    nbm_core_fhdelta = nbm_core_valid_end_datetime - core_init\n",
        "\n",
        "elif element == \"mint\":\n",
        "    nbm_core_valid_hour=\"12\"\n",
        "    nbm_qmd_valid_hour=\"18\"\n",
        "    valid_date_start = datetime.strptime(valid_date,'%Y-%m-%d')\n",
        "    valid_date_end = datetime.strptime(valid_date,'%Y-%m-%d')\n",
        "    obs_start_hour = \"0000\"\n",
        "    obs_end_hour = \"1800\"\n",
        "    ob_stat = \"minimum\"\n",
        "    valid_end_datetime = valid_date_end + timedelta(hours=(int(obs_end_hour)/100))\n",
        "    nbm_core_valid_end_datetime = valid_date_end + timedelta(hours=int(nbm_core_valid_hour))\n",
        "    nbm_qmd_valid_end_datetime = valid_date_end + timedelta(hours=int(nbm_qmd_valid_hour))\n",
        "    core_init = nbm_init + timedelta(hours = 7)\n",
        "    nbm_core_fhdelta = nbm_core_valid_end_datetime - core_init\n",
        "\n",
        "elif element == \"qpf\":\n",
        "    nbm_core_valid_hour = (str(qpf_valid_time)).zfill(2)\n",
        "    nbm_valid_hour = (str(qpf_valid_time)).zfill(2)\n",
        "    nbm_qmd_valid_hour=(str(qpf_valid_time)).zfill(2)\n",
        "    valid_date = datetime.strptime(valid_date,'%Y-%m-%d') + timedelta(hours=int(qpf_valid_time))\n",
        "    valid_date_start = valid_date - timedelta(hours=24)\n",
        "    valid_date_end = valid_date\n",
        "    obs_start_hour = (str(qpf_valid_time)).zfill(2)+\"00\"\n",
        "    obs_end_hour = (str(qpf_valid_time)).zfill(2)+\"00\"\n",
        "    ob_stat = \"total\"\n",
        "    valid_end_datetime = valid_date_end\n",
        "    core_init = nbm_init\n",
        "    nbm_core_valid_end_datetime = valid_date_end\n",
        "    nbm_qmd_valid_end_datetime = valid_date_end\n",
        "    nbm_core_fhdelta = nbm_core_valid_end_datetime - nbm_init\n",
        "\n",
        "elif element == \"maxwind\":\n",
        "    #nbm_core_valid_hour=\"06\"\n",
        "    #nbm_valid_hour=\"06\"\n",
        "    nbm_qmd_valid_hour=\"06\"\n",
        "    obs_start_hour=\"0600\"\n",
        "    obs_end_hour=\"0600\"\n",
        "    ob_stat=\"maximum\"\n",
        "    valid_date_start = datetime.strptime(valid_date,'%Y-%m-%d')\n",
        "    valid_date_end = datetime.strptime(valid_date,'%Y-%m-%d') + timedelta(days=1)\n",
        "    valid_end_datetime=valid_date_end + timedelta(hours=(int(obs_end_hour)/100))\n",
        "    core_init = nbm_init\n",
        "    nbm_core_valid_end_datetime = valid_date_end\n",
        "    nbm_qmd_valid_end_datetime = valid_date_end + timedelta(hours=int(nbm_qmd_valid_hour))\n",
        "    nbm_core_fhdelta = valid_end_datetime - nbm_init\n",
        "    #valid_date=date.strptime(valid_date,'') + timedelta(hours=)\n",
        "\n",
        "elif element == \"snow\":# or element == \"ice\":\n",
        "    nbm_core_valid_hour=(str(qpf_valid_time)).zfill(2)\n",
        "    nbm_qmd_valid_hour=(str(qpf_valid_time)).zfill(2)\n",
        "    obs_start_hour=(str(qpf_valid_time)).zfill(2)+\"00\"\n",
        "    obs_end_hour = (str(qpf_valid_time)).zfill(2)+\"00\"\n",
        "    valid_date = datetime.strptime(valid_date,'%Y-%m-%d') #+ timedelta(hours=int(qpf_valid_time))\n",
        "    valid_date_start = valid_date - timedelta(hours=24)\n",
        "    valid_date_end = valid_date\n",
        "    valid_end_datetime = valid_date_end + timedelta(hours=(int(obs_end_hour)/100))\n",
        "    ob_stat = \"total\"\n",
        "    core_init = nbm_init + timedelta(hours = 1)\n",
        "    nbm_qmd_valid_end_datetime = valid_date_end + timedelta(hours=int(nbm_qmd_valid_hour))\n",
        "    nbm_core_valid_end_datetime = nbm_qmd_valid_end_datetime\n",
        "    nbm_core_fhdelta = nbm_core_valid_end_datetime - core_init\n",
        "\n",
        "# Setup a dictionary for translating a form selection into a something we can pass to mesowest API\n",
        "network_dict = {\"NWS+RAWS+HADS\":\"&network=1,2,106\",\"NWS+RAWS\":\"&network=1,2\", \"NWS\":\"&network=1\", \"RAWS\": \"&network=2\", \"ALL\":\"\"}\n",
        "network_string = network_dict[network_selection]\n",
        "\n",
        "if element == \"qpf\":\n",
        "  cmap = get_cmap('BrBG')\n",
        "  cmap.set_under(color='black')\n",
        "  cmap.set_over(color='yellow')\n",
        "elif element == \"snow\":\n",
        "  cmap = get_cmap('cool_r')\n",
        "  cmap.set_under(color='black')\n",
        "  cmap.set_over(color='yellow')\n",
        "else:\n",
        "  #cmap = 'Spectral'\n",
        "  cmap = get_cmap('bwr')\n",
        "  cmap.set_under(color='yellow')\n",
        "  cmap.set_over(color='black')\n",
        "if use_stageiv and element==\"qpf\":\n",
        "  points_str = f'Stage IV @ {network_selection}'\n",
        "else:\n",
        "  points_str = network_selection\n",
        "\n",
        "if plot_style==\"light\":\n",
        "  background_color = '#f7f7f7'\n",
        "  text_color = '#121212'\n",
        "  map_land_color = '#FAFAF8'\n",
        "  map_water_color = '#D4DBDD'\n",
        "  map_border_color = 'grey'\n",
        "elif plot_style==\"dark\":\n",
        "  background_color = '#272727'\n",
        "  text_color = 'white'\n",
        "  map_land_color = '#414143'\n",
        "  map_water_color = '#272727'\n",
        "  #map_border_color = '#3B3B3D'\n",
        "  map_border_color = 'white'\n",
        "\n",
        "########################################################################################################################\n",
        "# Reusable functions section                                                                                           #\n",
        "########################################################################################################################\n",
        "\n",
        "def project3(lon, lat, prj):\n",
        "  lon = float(lon)\n",
        "  lat = float(lat)\n",
        "\n",
        "  outproj = prj\n",
        "  inproj = Proj(init='epsg:4326')\n",
        "  nbm_coords = transform(inproj, outproj, lon, lat)\n",
        "  coordX = nbm_coords[0]\n",
        "  coordY = nbm_coords[1]\n",
        "  #print(f'Lat: {lat}, Y: {coordY} | Lon: {lon}, X: {coordX}')\n",
        "  return(coordX, coordY)\n",
        "\n",
        "\n",
        "def ll_to_index(datalons, datalats, loclon, loclat):\n",
        "  abslat = np.abs(datalats-loclat)\n",
        "  abslon = np.abs(datalons-loclon)\n",
        "  c = np.maximum(abslon, abslat)\n",
        "  latlon_idx_flat = np.argmin(c)\n",
        "  latlon_idx = np.unravel_index(latlon_idx_flat, datalons.shape)\n",
        "  return(latlon_idx)\n",
        "\n",
        "\n",
        "def project_hrap(lon, lat, s4x, s4y):\n",
        "  lon = float(lon)\n",
        "  lat = float(lat)\n",
        "\n",
        "  globe = ccrs.Globe(semimajor_axis=6371200)\n",
        "  hrap_ccrs = proj = ccrs.Stereographic(central_latitude=90.0,\n",
        "                          central_longitude=255.0,\n",
        "                          true_scale_latitude=60.0, globe=globe)\n",
        "  latlon_ccrs = ccrs.PlateCarree()\n",
        "  hrap_coords = hrap_ccrs.transform_point(lon,lat,src_crs=latlon_ccrs)\n",
        "  hrap_idx = ll_to_index(s4x, s4y, hrap_coords[0], hrap_coords[1])\n",
        "\n",
        "  return hrap_idx\n",
        "\n",
        "def nohrsc_ll2ij(lon,lat,gridlons,gridlats):\n",
        "  #for a lat/lon grid\n",
        "  lon = float(lon)\n",
        "  lat = float(lat)\n",
        "  lonidx=(np.abs(lon-gridlons)).argmin()\n",
        "  latidx=(np.abs(lat-gridlats)).argmin()\n",
        "  return(latidx,lonidx)\n",
        "\n",
        "def get_stageiv():\n",
        "  siv_url = \"https://water.weather.gov/precip/downloads/\"+valid_date_end.strftime('%Y')+\"/\"+valid_date_end.strftime('%m')+\"/\"+valid_date_end.strftime('%d')+\"/nws_precip_1day_\"+valid_date_end.strftime('%Y%m%d')+\"_conus.nc\"\n",
        "  data = urlopen(siv_url).read()\n",
        "\n",
        "  nc = Dataset('data', memory=data)\n",
        "  #with Dataset(siv_file, 'r') as nc:\n",
        "  stageIV = nc.variables['observation']\n",
        "  s4x = nc.variables['x']\n",
        "  s4y = nc.variables['y']\n",
        "  return stageIV, s4x, s4y\n",
        "\n",
        "def get_nohrsc():\n",
        "  nohrsc_url = \"https://www.nohrsc.noaa.gov/snowfall_v2/data/\"+valid_date_end.strftime('%Y%m')+\"/sfav2_CONUS_24h_\"+valid_date_end.strftime('%Y%m%d%H')+\".nc\"\n",
        "  data = urlopen(nohrsc_url).read()\n",
        "\n",
        "  nc = Dataset('data',memory=data)\n",
        "  snow=np.asarray(nc.variables['Data']) #make lon by lat array (original lat by lon)\n",
        "  snowlat = np.asarray(nc.variables['lat'])\n",
        "  snowlon = np.asarray(nc.variables['lon'])\n",
        "  return snow,snowlon,snowlat\n",
        "\n",
        "def K_to_F(kelvin):\n",
        "  fahrenheit = 1.8*(kelvin-273)+32.\n",
        "  return fahrenheit\n",
        "\n",
        "def mps_to_kts(mps):\n",
        "  kts = mps * 1.94384\n",
        "  return kts\n",
        "\n",
        "def mm_to_in(millimeters):\n",
        "  inches = millimeters * 0.0393701\n",
        "  return inches\n",
        "\n",
        "def meters_to_in(meters):\n",
        "  inches = meters*39.3701\n",
        "  return inches\n",
        "\n",
        "def find_roots(x,y):\n",
        "  s = np.abs(np.diff(np.sign(y))).astype(bool)\n",
        "  return x[:-1][s] + np.diff(x)[s]/(np.abs(y[1:][s]/y[:-1][s])+1)\n"
      ],
      "metadata": {
        "id": "KHNSqQwLHqVj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download Obs\n",
        "\n",
        "current_datetime = datetime.now()\n",
        "\n",
        "synoptic_token = \"62e9269f0a164da1b2415ddcf8f4f29e\"\n",
        "statistics_api = \"https://api.synopticlabs.org/v2/stations/statistics?\"\n",
        "precipitation_api = \"https://api.synopticdata.com/v2/stations/precipitation?\"\n",
        "metadata_api = \"https://api.synopticdata.com/v2/stations/metadata?\"\n",
        "\n",
        "print('Getting obs...')\n",
        "obs ={}\n",
        "\n",
        "for region in region_list:\n",
        "  if (valid_end_datetime <= current_datetime):\n",
        "    print(\"   > Grabbing obs for: \", region)\n",
        "    #print(\"List of CWAs: \", cwa_list(region) )\n",
        "    json_name = \"obs/Obs_\"+element+\"_\"+valid_date_start.strftime('%Y%m%d')+obs_start_hour+\"_\"+valid_date_end.strftime('%Y%m%d')+obs_end_hour+\"_\"+region+\".json\"\n",
        "    if os.path.exists(\"obs\"):\n",
        "      pass\n",
        "    else:\n",
        "      os.mkdir(\"obs\")\n",
        "    if element == \"mint\" or element == \"maxt\":\n",
        "      api_token = \"&token=\"+synoptic_token\n",
        "      station_query = \"&cwa=\"+cwa_list(region)\n",
        "      vars_query = \"&vars=air_temp\"\n",
        "      start_query = \"&start=\"+valid_date_start.strftime('%Y%m%d')+obs_start_hour\n",
        "      end_query = \"&end=\"+valid_date_end.strftime('%Y%m%d')+obs_end_hour\n",
        "      stat_type = \"&type=\"+ob_stat\n",
        "      network_query = network_string\n",
        "      api_extras = \"&units=temp%7Cf&within=1440&status=active\"\n",
        "      obs_url = statistics_api + api_token + station_query + vars_query + start_query + end_query + stat_type + network_query + api_extras\n",
        "    elif element == \"maxwind\":\n",
        "      api_token = \"&token=\"+synoptic_token\n",
        "      station_query = \"&cwa=\"+cwa_list(region)\n",
        "      vars_query = \"&vars=wind_speed\"\n",
        "      start_query = \"&start=\"+valid_date_start.strftime('%Y%m%d')+obs_start_hour\n",
        "      end_query = \"&end=\"+valid_date_end.strftime('%Y%m%d')+obs_end_hour\n",
        "      stat_type = \"&type=\"+ob_stat\n",
        "      network_query = network_string\n",
        "      obs_url = statistics_api + api_token + station_query + vars_query + start_query + end_query + stat_type + network_query\n",
        "    elif element == \"qpf\":\n",
        "      if use_stageiv:\n",
        "        api_token = \"&token=\"+synoptic_token\n",
        "        station_query = \"&cwa=\"+cwa_list(region)\n",
        "        api_extras = \"&fields=status,latitude,longitude,name,elevation\"\n",
        "        network_query = network_string\n",
        "        obs_url = metadata_api + api_token + station_query + network_query + api_extras\n",
        "        stageIV, s4xs, s4ys = get_stageiv()\n",
        "        s4xs, s4ys = np.meshgrid(s4xs, s4ys)\n",
        "      else:\n",
        "        api_token = \"&token=\"+synoptic_token\n",
        "        station_query = \"&cwa=\"+cwa_list(region)\n",
        "        api_extras = \"&fields=status,latitude,longitude,name,elevation&obtimezone=utc\"\n",
        "        network_query = network_string\n",
        "        vars_query = \"&pmode=totals\"\n",
        "        units_query = \"&units=precip|in\"\n",
        "        start_query = \"&start=\"+valid_date_start.strftime('%Y%m%d')+obs_start_hour\n",
        "        end_query = \"&end=\"+valid_date_end.strftime('%Y%m%d')+obs_end_hour\n",
        "        obs_url = precipitation_api + api_token + station_query + network_query + vars_query + start_query + end_query + units_query + api_extras\n",
        "    elif element == \"snow\":\n",
        "      if use_nohrsc:\n",
        "        api_token = \"&token=\"+synoptic_token\n",
        "        station_query = \"&cwa=\"+cwa_list(region)\n",
        "        api_extras = \"&fields=status,latitude,longitude,name,elevation\"\n",
        "        network_query = network_string\n",
        "        obs_url = metadata_api + api_token + station_query + network_query + api_extras\n",
        "        snow,snowlon,snowlat = get_nohrsc()\n",
        "        snowlons,snowlats = np.meshgrid(snowlon,snowlat)\n",
        "      else:\n",
        "        api_token = \"&token=\"+synoptic_token\n",
        "        station_query = \"&cwa=\"+cwa_list(region)\n",
        "        api_extras = \"&fields=status,latitude,longitude,name,elevation&obtimezone=utc\"\n",
        "        network_query = network_string\n",
        "        vars_query = \"&pmode=totals\"\n",
        "        units_query = \"&units=precip|in\"\n",
        "        start_query = \"&start=\"+valid_date_start.strftime('%Y%m%d')+obs_start_hour\n",
        "        end_query = \"&end=\"+valid_date_end.strftime('%Y%m%d')+obs_end_hour\n",
        "        obs_url = precipitation_api + api_token + station_query + network_query + vars_query + start_query + end_query + units_query + api_extras\n",
        "    print(\"Obs url: \" + obs_url)\n",
        "    if os.path.exists(json_name):\n",
        "      print (\"Skipping download since JSON file already exists\")\n",
        "      pass\n",
        "    else:\n",
        "      urlretrieve(obs_url, json_name)\n",
        "\n",
        "    if os.path.exists(json_name):\n",
        "        with open(json_name) as json_file:\n",
        "            obs_json = json.load(json_file)\n",
        "            print (\"Loaded Obs JSON file line 343: \" + json_name)\n",
        "            obs_lats = []\n",
        "            obs_lons = []\n",
        "            obs_value = []\n",
        "            obs_elev = []\n",
        "            obs_stid = []\n",
        "            obs_name = []\n",
        "            for stn in obs_json[\"STATION\"]:\n",
        "                if stn[\"STID\"] is None:\n",
        "                  stid = \"N0N3\"\n",
        "                else:\n",
        "                  stid = stn[\"STID\"]\n",
        "                name = stn[\"NAME\"]\n",
        "                if stn[\"ELEVATION\"] and stn[\"ELEVATION\"] is not None:\n",
        "                  elev = stn[\"ELEVATION\"]\n",
        "                else:\n",
        "                  elev = -999\n",
        "                lat = stn[\"LATITUDE\"]\n",
        "                lon = stn[\"LONGITUDE\"]\n",
        "                if float(lon) > -50:\n",
        "                  continue #bug fix to deal with errant synoptic labs obs in the file\n",
        "                if element == \"mint\" or element==\"maxt\":\n",
        "                  if 'air_temp_set_1' in stn['STATISTICS'] and stn['STATISTICS']['air_temp_set_1']:\n",
        "                    if ob_stat in stn['STATISTICS']['air_temp_set_1']: # and float(stn[\"LATITUDE\"]) != 0. and float(stn[\"LONGITUDE\"]) != 0.:\n",
        "                      stat = stn['STATISTICS']['air_temp_set_1'][ob_stat]\n",
        "                      obs_stid.append(str(stid))\n",
        "                      obs_name.append(str(name))\n",
        "                      obs_elev.append(float(elev))\n",
        "                      obs_lats.append(float(lat))\n",
        "                      obs_lons.append(float(lon))\n",
        "                      obs_value.append(float(stat))\n",
        "                elif element == \"maxwind\":\n",
        "                  if 'wind_speed_set_1' in stn['STATISTICS'] and stn['STATISTICS']['wind_speed_set_1']:\n",
        "                    if ob_stat in stn['STATISTICS']['wind_speed_set_1']: # and float(stn[\"LATITUDE\"]) != 0.:\n",
        "                      stat = stn['STATISTICS']['wind_speed_set_1'][ob_stat]\n",
        "                      obs_stid.append(str(stid))\n",
        "                      obs_name.append(str(name))\n",
        "                      obs_elev.append(float(elev))\n",
        "                      obs_lats.append(float(lat))\n",
        "                      obs_lons.append(float(lon))\n",
        "                      obs_value.append(mps_to_kts(float(stat)))\n",
        "                elif (element == \"qpf\"):\n",
        "                  if (stn[\"STATUS\"] == \"ACTIVE\"): # and float(stn[\"LATITUDE\"]) < 50.924 and float(stn[\"LATITUDE\"]) > 23.377 and float(stn[\"LONGITUDE\"]) > -125.650 and float(stn[\"LONGITUDE\"]) < -66.008:\n",
        "                    obs_stid.append(str(stid))\n",
        "                    obs_name.append(str(name))\n",
        "                    obs_elev.append(float(elev))\n",
        "                    obs_lats.append(float(lat))\n",
        "                    obs_lons.append(float(lon))\n",
        "                    if use_stageiv:\n",
        "                      coords = project_hrap(lon, lat, s4xs, s4ys)\n",
        "                      siv_value = float(stageIV[coords])\n",
        "                      if (siv_value >= 0.01):\n",
        "                        obs_value.append(siv_value)\n",
        "                      else:\n",
        "                        obs_value.append(0.0)\n",
        "                    else:\n",
        "                      if \"precipitation\" in stn[\"OBSERVATIONS\"]:\n",
        "                        if \"total\" in stn[\"OBSERVATIONS\"][\"precipitation\"][0]:\n",
        "                          ptotal = stn[\"OBSERVATIONS\"][\"precipitation\"][0][\"total\"]\n",
        "                          if ptotal >= 0.005:\n",
        "                            obs_value.append(ptotal)\n",
        "                          else:\n",
        "                            obs_value.append(0.0)\n",
        "                        else:\n",
        "                          obs_value.append(np.nan)\n",
        "                      else:\n",
        "                        obs_value.append(np.nan)\n",
        "                elif (element == \"snow\"):\n",
        "                  if stn[\"STATUS\"] == \"ACTIVE\": # and float(stn[\"LATITUDE\"]) < 50.924)and float(stn[\"LATITUDE\"]) > 23.377 and float(stn[\"LONGITUDE\"]) > -125.650 and float(stn[\"LONGITUDE\"]) < -66.008:\n",
        "                    obs_stid.append(str(stid))\n",
        "                    obs_name.append(str(name))\n",
        "                    obs_elev.append(float(elev))\n",
        "                    obs_lats.append(float(lat))\n",
        "                    obs_lons.append(float(lon))\n",
        "                    if use_nohrsc:\n",
        "                      coords = nohrsc_ll2ij(lon,lat,snowlon,snowlat)\n",
        "                      nohrsc_value = meters_to_in(float(snow[coords]))\n",
        "                      if nohrsc_value >= 0.005:\n",
        "                        obs_value.append(nohrsc_value)\n",
        "                      elif nohrsc_value < 0.0:\n",
        "                        obs_value.append(np.nan)\n",
        "                      else:\n",
        "                        obs_value.append(0.0)\n",
        "                    else:\n",
        "                      raise Exception(\"Still not able to process individual snow obs!\")\n",
        "            csv_name = \"obs_\"+element+\"_\"+region+\".csv\"\n",
        "            obs[region] = pd.DataFrame()\n",
        "            obs[region][\"stid\"] = obs_stid\n",
        "            obs[region][\"name\"] = obs_name\n",
        "            obs[region][\"elevation\"] = obs_elev\n",
        "            obs[region][\"lat\"] = obs_lats\n",
        "            obs[region][\"lon\"] = obs_lons\n",
        "            obs[region][\"ob_\"+element] = obs_value\n",
        "            obs[region].dropna(inplace=True)\n",
        "            obs[region].to_csv(csv_name)\n",
        "  else:\n",
        "    print(f'    > Valid Time in the future. Grabbing obs points only for: {region}')\n",
        "    json_name = \"obs/ObsPoints_\"+region+\"_wcoss.json\"\n",
        "    if os.path.exists(json_name):\n",
        "      pass\n",
        "    else:\n",
        "      if os.path.exists(\"obs\"):\n",
        "        pass\n",
        "      else:\n",
        "        os.mkdir(\"obs\")\n",
        "      obs_url = \"https://api.synopticdata.com/v2/stations/metadata?&token=\"+synoptic_token+\"&cwa=\"+cwa_list(region)+\"&fields=status,latitude,longitude,name,elevation\"+network_string\n",
        "      urlretrieve(obs_url, json_name)\n",
        "    if os.path.exists(json_name):\n",
        "      with open(json_name) as json_file:\n",
        "          obs_json = json.load(json_file)\n",
        "          print(\"Loaded Obs JSON file line 197!\")\n",
        "          obs_lats = []\n",
        "          obs_lons = []\n",
        "          obs_elev = []\n",
        "          obs_stid = []\n",
        "          obs_name = []\n",
        "          for stn in obs_json[\"STATION\"]:\n",
        "            # print(stn.encode('utf-8'))\n",
        "            if stn[\"STID\"] is None:\n",
        "              stid = \"N0N3\"\n",
        "            else:\n",
        "              stid = stn[\"STID\"]\n",
        "            #print(f'Processing {region} station {stid}')\n",
        "            name = stn[\"NAME\"]\n",
        "            if stn[\"ELEVATION\"] and stn[\"ELEVATION\"] is not None:\n",
        "              elev = stn[\"ELEVATION\"]\n",
        "            else:\n",
        "              elev = -999\n",
        "            lat = stn[\"LATITUDE\"]\n",
        "            lon = stn[\"LONGITUDE\"]\n",
        "            if stn[\"STATUS\"] == \"ACTIVE\": # and float(stn[\"LATITUDE\"]) != 0. and float(stn[\"LONGITUDE\"]) != 0.:\n",
        "              obs_stid.append(str(stid))\n",
        "              obs_name.append(str(name))\n",
        "              obs_elev.append(float(elev))\n",
        "              obs_lats.append(float(lat))\n",
        "              obs_lons.append(float(lon))\n",
        "          obs[region] = pd.DataFrame()\n",
        "          obs[region][\"stid\"] = obs_stid\n",
        "          obs[region][\"name\"] = obs_name\n",
        "          obs[region][\"elevation\"] = obs_elev\n",
        "          obs[region][\"lat\"] = obs_lats\n",
        "          obs[region][\"lon\"] = obs_lons\n",
        "          obs[region][\"ob_\"+element] = -999\n",
        "          obs[region].dropna(inplace=True)\n",
        "          #obs[region].to_csv(csv_name)"
      ],
      "metadata": {
        "id": "DX9ZfztpLfgU",
        "outputId": "9cbc5ba7-40de-4771-a04f-f8412784797a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting obs...\n",
            "   > Grabbing obs for:  ER\n",
            "Obs url: https://api.synopticlabs.org/v2/stations/statistics?&token=62e9269f0a164da1b2415ddcf8f4f29e&cwa=ALY,LWX,BGM,BOX,BUF,BTV,CAR,CTP,RLX,CHS,ILN,CLE,CAE,GSP,MHX,OKX,PHI,PBZ,GYX,RAH,RNK,AKQ,ILM&vars=air_temp&start=202402040000&end=202402041800&type=minimum&network=1,2&units=temp%7Cf&within=1440&status=active\n",
            "Loaded Obs JSON file line 343: obs/Obs_mint_202402040000_202402041800_ER.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdate=\"202310251300\"\n",
        "vdate=\"202310271200\"\n",
        "\n",
        "obframe=pd.read_csv('allprobbs_'+rdate+'_'+vdate+'.csv',index_col=0)\n",
        "\n",
        "nbm_init=datetime.strptime(rdate,'%Y%m%d%H%M')\n",
        "valdate=datetime.strptime(vdate,'%Y%m%d%H%M')\n",
        "\n",
        "matplotlib.rc('axes',facecolor=background_color,edgecolor=text_color)\n",
        "fig_valid_date=valdate.strftime('%Y%m%d_%HZ')\n",
        "valid_title=valdate.strftime('%HZ %a %m-%d-%Y')\n",
        "nbm_init_title=nbm_init.strftime('%HZ %m-%d-%Y')\n",
        "nbm_init_string=nbm_init.strftime('%Y%m%d_%H') + \"Z\"\n",
        "\n",
        "print(\"Making plot for custom region!\")\n",
        "west = np.nanmin(obframe[\"lon\"]) - 0.5\n",
        "south = np.nanmin(obframe[\"lat\"]) - 0.5\n",
        "east = np.nanmax(obframe[\"lon\"]) + 1.0\n",
        "north = np.nanmax(obframe[\"lat\"]) + 0.5\n",
        "width, height = (16,9)\n",
        "ratioxy = 16./9.\n",
        "width_ratios = [ratioxy]#, 1]\n",
        "proj = ccrs.PlateCarree()\n",
        "print(\"Plot dimensions have been set up!\")\n",
        "\n",
        "fig = plt.figure(constrained_layout=True, figsize=(width,height), facecolor=background_color, frameon=True, dpi=150)\n",
        "grid = fig.add_gridspec(1,1, hspace=0.1, width_ratios=width_ratios, height_ratios = [1], wspace=0.2)\n",
        "ax1 = fig.add_subplot(grid[0,0], projection=ccrs.Mercator())\n",
        "ax1.set_anchor('N')\n",
        "ax1.set_facecolor(background_color)\n",
        "ax1.set_extent([west, east, south, north], crs=proj)\n",
        "ax1.add_feature(cfeature.OCEAN, edgecolor='none', facecolor=map_water_color, zorder=-2)\n",
        "ax1.add_feature(cfeature.NaturalEarthFeature('physical', 'land', '50m', edgecolor='none', facecolor=map_land_color, zorder=-1))\n",
        "#ax1.add_feature(cfeature.LAKES, edgecolor='none', facecolor='#272727', zorder=0)\n",
        "ax1.add_feature(cfeature.NaturalEarthFeature('physical', 'lakes', '10m', edgecolor='none', facecolor=map_water_color, zorder=0))\n",
        "ax1.add_feature(cfeature.BORDERS, edgecolor=map_border_color, facecolor='none', linewidth=2, zorder=1)\n",
        "#ax1.add_feature(cfeature.NaturalEarthFeature('cultural', 'countries', '50m', edgecolor=map_border_color, facecolor='none', linewidth=2, zorder=2))\n",
        "ax1.add_feature(cfeature.NaturalEarthFeature('cultural', 'admin_1_states_provinces_lines', '50m', edgecolor=map_border_color, facecolor='none', linewidth=1, zorder=2))\n",
        "\n",
        "hitframe=obframe[obframe[\"Hit_1.0\"] == \"HIT\"]\n",
        "hitscat=ax1.scatter(hitframe[\"lon\"].values,hitframe[\"lat\"].values,color=\"limegreen\",transform=proj)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "4ppum_jM8jK7",
        "outputId": "1017c1c4-8c08-4c0c-d5dc-d713026c2581"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'allprobbs_202310251300_202310271200.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-7205d72422da>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mvdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"202310271200\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mobframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allprobbs_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mrdate\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mvdate\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mnbm_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'%Y%m%d%H%M'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'allprobbs_202310251300_202310271200.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "usgCFamy-5Yn"
      }
    }
  ]
}